{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-27T03:20:55.851930Z",
     "start_time": "2024-09-27T03:19:17.024010Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Load the preprocessed data\n",
    "X_train = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/X_train.txt\")\n",
    "y_train = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/y_train.txt\")\n",
    "X_test = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/X_test.txt\")\n",
    "y_test = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/y_test.txt\")\n",
    "\n",
    "# Reshape the input data for Conv1D layers\n",
    "n_timestep = 100\n",
    "n_features = 9\n",
    "X_train = X_train.reshape(X_train.shape[0], n_timestep, n_features)\n",
    "X_test = X_test.reshape(X_test.shape[0], n_timestep, n_features)\n",
    "\n",
    "# One-hot encode the labels\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)\n",
    "\n",
    "\n",
    "def create_model(n_timesteps, n_features, n_outputs):\n",
    "    model = Sequential([\n",
    "        # Conv2D to emulate Conv1D by using height = 1 and kernel size (1, 3)\n",
    "        Conv2D(filters=64, kernel_size=(1, 3), activation=\"relu\", input_shape=(n_timesteps, n_features, 1)),\n",
    "        Conv2D(filters=64, kernel_size=(1, 3), activation=\"relu\"),\n",
    "\n",
    "        # Flatten instead of GlobalAveragePooling1D\n",
    "        Flatten(),\n",
    "\n",
    "        # Dense layers\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(n_outputs, activation=\"softmax\")\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "n_outputs = y_train.shape[1]\n",
    "conv_mlp = create_model(n_timestep, n_features, n_outputs)\n",
    "conv_mlp.compile(optimizer=Adam(learning_rate=0.001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = conv_mlp.fit(X_train, y_train, epochs=50, batch_size=512, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = conv_mlp.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true_classes, y_pred_classes, digits=5))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 09:19:17.209205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-27 09:19:17.220219: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-27 09:19:17.223474: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-27 09:19:17.232427: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-27 09:19:17.730075: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/denuvo-drm/miniconda3/envs/CompositeADLRecognition/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727407179.211862   86040 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727407179.244503   86040 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727407179.247499   86040 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727407179.251918   86040 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727407179.254663   86040 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727407179.257583   86040 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727407179.359666   86040 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727407179.360830   86040 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727407179.361928   86040 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-27 09:19:39.362985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5653 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:0e:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727407180.603454   86419 service.cc:146] XLA service 0x736668005ac0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1727407180.603483   86419 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-09-27 09:19:40.623109: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-27 09:19:40.727685: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-09-27 09:19:41.806818: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_534', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2024-09-27 09:19:41.893796: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_534', 336 bytes spill stores, 336 bytes spill loads\n",
      "\n",
      "2024-09-27 09:19:41.912586: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_455', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2024-09-27 09:19:42.031218: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_534', 324 bytes spill stores, 324 bytes spill loads\n",
      "\n",
      "2024-09-27 09:19:42.987895: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.20GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m 22/156\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.2747 - loss: 2.4065"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727407183.695923   86419 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m155/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5692 - loss: 1.3955"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 09:19:47.078126: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.61GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 40ms/step - accuracy: 0.5710 - loss: 1.3895 - val_accuracy: 0.7005 - val_loss: 0.9739\n",
      "Epoch 2/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8330 - loss: 0.4961 - val_accuracy: 0.7219 - val_loss: 0.9725\n",
      "Epoch 3/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8858 - loss: 0.3436 - val_accuracy: 0.7095 - val_loss: 1.1152\n",
      "Epoch 4/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9085 - loss: 0.2700 - val_accuracy: 0.7154 - val_loss: 1.2308\n",
      "Epoch 5/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9273 - loss: 0.2153 - val_accuracy: 0.7278 - val_loss: 1.1993\n",
      "Epoch 6/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9414 - loss: 0.1750 - val_accuracy: 0.7067 - val_loss: 1.3897\n",
      "Epoch 7/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9510 - loss: 0.1479 - val_accuracy: 0.7426 - val_loss: 1.3506\n",
      "Epoch 8/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9587 - loss: 0.1231 - val_accuracy: 0.7234 - val_loss: 1.4240\n",
      "Epoch 9/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9688 - loss: 0.0958 - val_accuracy: 0.7288 - val_loss: 1.4451\n",
      "Epoch 10/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9701 - loss: 0.0893 - val_accuracy: 0.7167 - val_loss: 1.7367\n",
      "Epoch 11/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9705 - loss: 0.0848 - val_accuracy: 0.7209 - val_loss: 1.7018\n",
      "Epoch 12/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9787 - loss: 0.0642 - val_accuracy: 0.7251 - val_loss: 1.6380\n",
      "Epoch 13/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9788 - loss: 0.0614 - val_accuracy: 0.7415 - val_loss: 1.8066\n",
      "Epoch 14/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9813 - loss: 0.0565 - val_accuracy: 0.7237 - val_loss: 1.8866\n",
      "Epoch 15/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9782 - loss: 0.0649 - val_accuracy: 0.7301 - val_loss: 1.9646\n",
      "Epoch 16/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9828 - loss: 0.0505 - val_accuracy: 0.7193 - val_loss: 2.0102\n",
      "Epoch 17/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9857 - loss: 0.0431 - val_accuracy: 0.7187 - val_loss: 2.0544\n",
      "Epoch 18/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9861 - loss: 0.0412 - val_accuracy: 0.7133 - val_loss: 2.1917\n",
      "Epoch 19/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9857 - loss: 0.0437 - val_accuracy: 0.7169 - val_loss: 2.2026\n",
      "Epoch 20/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9912 - loss: 0.0286 - val_accuracy: 0.7277 - val_loss: 2.2917\n",
      "Epoch 21/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9883 - loss: 0.0361 - val_accuracy: 0.7271 - val_loss: 2.2512\n",
      "Epoch 22/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9878 - loss: 0.0366 - val_accuracy: 0.7350 - val_loss: 2.2005\n",
      "Epoch 23/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9887 - loss: 0.0320 - val_accuracy: 0.7252 - val_loss: 2.3453\n",
      "Epoch 24/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9901 - loss: 0.0292 - val_accuracy: 0.7222 - val_loss: 2.4431\n",
      "Epoch 25/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9885 - loss: 0.0344 - val_accuracy: 0.7146 - val_loss: 2.5549\n",
      "Epoch 26/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9862 - loss: 0.0394 - val_accuracy: 0.7267 - val_loss: 2.4509\n",
      "Epoch 27/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9917 - loss: 0.0244 - val_accuracy: 0.7324 - val_loss: 2.4310\n",
      "Epoch 28/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9898 - loss: 0.0296 - val_accuracy: 0.7298 - val_loss: 2.2939\n",
      "Epoch 29/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9915 - loss: 0.0249 - val_accuracy: 0.7214 - val_loss: 2.5850\n",
      "Epoch 30/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9895 - loss: 0.0308 - val_accuracy: 0.7385 - val_loss: 2.4803\n",
      "Epoch 31/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9915 - loss: 0.0238 - val_accuracy: 0.7253 - val_loss: 2.6407\n",
      "Epoch 32/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9923 - loss: 0.0227 - val_accuracy: 0.7335 - val_loss: 2.6090\n",
      "Epoch 33/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9924 - loss: 0.0222 - val_accuracy: 0.7212 - val_loss: 2.6945\n",
      "Epoch 34/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9927 - loss: 0.0213 - val_accuracy: 0.7218 - val_loss: 2.7894\n",
      "Epoch 35/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9922 - loss: 0.0235 - val_accuracy: 0.7108 - val_loss: 2.9574\n",
      "Epoch 36/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9888 - loss: 0.0353 - val_accuracy: 0.7326 - val_loss: 2.6147\n",
      "Epoch 37/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9912 - loss: 0.0266 - val_accuracy: 0.7127 - val_loss: 2.7982\n",
      "Epoch 38/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9922 - loss: 0.0222 - val_accuracy: 0.7241 - val_loss: 2.8042\n",
      "Epoch 39/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9961 - loss: 0.0121 - val_accuracy: 0.7425 - val_loss: 2.8675\n",
      "Epoch 40/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9963 - loss: 0.0118 - val_accuracy: 0.7200 - val_loss: 2.9800\n",
      "Epoch 41/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9924 - loss: 0.0245 - val_accuracy: 0.7216 - val_loss: 2.8102\n",
      "Epoch 42/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9912 - loss: 0.0264 - val_accuracy: 0.7254 - val_loss: 2.9030\n",
      "Epoch 43/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9928 - loss: 0.0217 - val_accuracy: 0.7266 - val_loss: 2.7888\n",
      "Epoch 44/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9954 - loss: 0.0142 - val_accuracy: 0.7373 - val_loss: 2.7743\n",
      "Epoch 45/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9940 - loss: 0.0198 - val_accuracy: 0.7232 - val_loss: 2.9921\n",
      "Epoch 46/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9952 - loss: 0.0134 - val_accuracy: 0.7275 - val_loss: 2.9784\n",
      "Epoch 47/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9934 - loss: 0.0203 - val_accuracy: 0.7249 - val_loss: 3.0511\n",
      "Epoch 48/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9978 - loss: 0.0074 - val_accuracy: 0.7381 - val_loss: 3.0298\n",
      "Epoch 49/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9956 - loss: 0.0132 - val_accuracy: 0.7122 - val_loss: 3.3822\n",
      "Epoch 50/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.9955 - loss: 0.0133 - val_accuracy: 0.7339 - val_loss: 3.0868\n",
      "\u001B[1m616/616\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.77340   0.84682   0.80844       927\n",
      "           1    0.93711   0.96440   0.95056       927\n",
      "           2    0.81537   0.82684   0.82106       924\n",
      "           3    0.97800   0.65906   0.78747       877\n",
      "           4    0.73433   0.52008   0.60891       946\n",
      "           5    0.64332   0.63511   0.63919       940\n",
      "           6    0.64108   0.90254   0.74967       944\n",
      "           7    0.59380   0.82632   0.69102       950\n",
      "           8    0.76812   0.27865   0.40895       951\n",
      "           9    0.48320   0.32578   0.38918       927\n",
      "          10    0.76318   0.68986   0.72467      1322\n",
      "          11    0.57811   0.83333   0.68264       564\n",
      "          12    0.84661   0.91104   0.87765       933\n",
      "          13    0.72648   0.89293   0.80115       934\n",
      "          14    0.56009   0.55532   0.55769       940\n",
      "          15    0.58226   0.58728   0.58476       928\n",
      "          16    0.94187   0.99376   0.96712       962\n",
      "          17    0.17439   0.06716   0.09697       953\n",
      "          18    0.48908   0.54440   0.51526       946\n",
      "          19    0.75704   0.67752   0.71508       952\n",
      "          20    0.46292   0.80962   0.58904       956\n",
      "\n",
      "    accuracy                        0.68015     19703\n",
      "   macro avg    0.67856   0.68323   0.66507     19703\n",
      "weighted avg    0.68072   0.68015   0.66496     19703\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T03:21:23.859416Z",
     "start_time": "2024-09-27T03:21:15.904645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(conv_mlp)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model\n",
    "with open(\"GeneratedTFLiteFilesAndOGModels/conv_mlp_model_deploy.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"TensorFlow Lite model has been saved as 'conv_mlp_model_deploy.tflite'\")\n",
    "\n",
    "# Optional: Save the Keras model\n",
    "conv_mlp.save(\"GeneratedTFLiteFilesAndOGModels/conv_mlp_model_deploy.h5\")\n",
    "print(\"Keras model has been saved as 'conv_mlp_model_deploy.h5'\")\n",
    "\n",
    "# If you still need to generate a C header file\n",
    "try:\n",
    "    from everywhereml.code_generators.tensorflow import convert_model\n",
    "\n",
    "    c_header = convert_model(conv_mlp, X_test, y_test, model_name='conv_mlp_model_deploy')\n",
    "\n",
    "    with open(\"GeneratedHeaderFiles/conv_mlp_model.h\", \"w\") as file:\n",
    "        file.write(c_header)\n",
    "\n",
    "    print(\"C header file has been saved as GeneratedHeaderFiles/conv_mlp_model.h'\")\n",
    "except ImportError:\n",
    "    print(\"everywhereml library not found. Skipping C header file generation.\")\n"
   ],
   "id": "b52dcf7c1dced840",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpoqzuhgfs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpoqzuhgfs/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpoqzuhgfs'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 100, 9, 1), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 21), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  126891561007968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561323328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561323504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561327024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561322448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561328608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561322800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561330192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561320512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561331776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1727407276.210685   86040 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1727407276.210700   86040 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "2024-09-27 09:21:16.210905: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpoqzuhgfs\n",
      "2024-09-27 09:21:16.211245: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-09-27 09:21:16.211254: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpoqzuhgfs\n",
      "2024-09-27 09:21:16.214246: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-09-27 09:21:16.214836: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-09-27 09:21:16.249744: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpoqzuhgfs\n",
      "2024-09-27 09:21:16.255516: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 44613 microseconds.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Lite model has been saved as 'conv_mlp_model_deploy.tflite'\n",
      "Keras model has been saved as 'conv_mlp_model_deploy.h5'\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpkn1m_n_7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpkn1m_n_7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpkn1m_n_7'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 100, 9, 1), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 21), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  126891561007968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561323328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561323504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561327024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561322448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561328608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561322800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561330192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561320512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  126891561331776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1727407276.857781   86040 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1727407276.857793   86040 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "2024-09-27 09:21:16.857909: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpkn1m_n_7\n",
      "2024-09-27 09:21:16.858252: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-09-27 09:21:16.858261: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpkn1m_n_7\n",
      "2024-09-27 09:21:16.861262: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-09-27 09:21:16.918122: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpkn1m_n_7\n",
      "2024-09-27 09:21:16.925088: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 67181 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C header file has been saved as GeneratedHeaderFiles/conv_mlp_model.h'\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T03:21:30.557626Z",
     "start_time": "2024-09-27T03:21:26.550714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing out the TFLite model when optimized for normal edge devices\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Loading the test data\n",
    "X_test = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/X_test.txt\")\n",
    "y_test = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/y_test.txt\")\n",
    "\n",
    "# Reshaping the input data\n",
    "n_timestep = 100\n",
    "n_features = 9\n",
    "X_test = X_test.reshape(X_test.shape[0], n_timestep, n_features)\n",
    "\n",
    "# Doing One-hot encode the labels\n",
    "lb = LabelBinarizer()\n",
    "y_test = lb.fit_transform(y_test)\n",
    "\n",
    "# Loading the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"GeneratedTFLiteFilesAndOGModels/conv_mlp_model_deploy.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Allocating input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data\n",
    "input_shape = input_details[0][\"shape\"]\n",
    "input_data = X_test\n",
    "\n",
    "# Now running predictions on every test sample\n",
    "y_pred_tflite = []\n",
    "for i in range(len(input_data)):\n",
    "    input_tensor = np.array(input_data[i], dtype=np.float32)\n",
    "    input_tensor = np.expand_dims(input_tensor, axis=0)\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], input_tensor)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "    y_pred_tflite.append(output_data)\n",
    "\n",
    "y_pred_tflite = np.vstack(y_pred_tflite)\n",
    "\n",
    "# Converting predictions to class labels\n",
    "y_pred_classes_tflite = np.argmax(y_pred_tflite, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculating the accuracy\n",
    "accuracy_tflite = accuracy_score(y_true_classes, y_pred_classes_tflite)\n",
    "print(f\"TFLite Model Accuracy: {accuracy_tflite:.5f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes_tflite, digits=5))\n",
    "\n",
    "try:\n",
    "    original_model = tf.keras.models.load_model(\"GeneratedTFLiteFilesAndOGModels/conv_mlp_model_deploy.h5\")\n",
    "    y_pred_original = original_model.predict(X_test)\n",
    "    y_pred_classes_original = np.argmax(y_pred_original, axis=1)\n",
    "    accuracy_original = accuracy_score(y_true_classes, y_pred_classes_original)\n",
    "    print(f\"\\nOriginal Keras Model Accuracy: {accuracy_original:.5f}\")\n",
    "\n",
    "    prediction_match = np.mean(y_pred_classes_tflite == y_pred_classes_original)\n",
    "    print(f\"\\nPrediction Match between TFLite and Original model: {prediction_match:.5f}\")\n",
    "except:\n",
    "    print(\"\\nError Check your path\")"
   ],
   "id": "460956467dbb2a71",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 0.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 34\u001B[0m\n\u001B[1;32m     32\u001B[0m input_tensor \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(input_data[i], dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m     33\u001B[0m input_tensor \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(input_tensor, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m---> 34\u001B[0m \u001B[43minterpreter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_details\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mindex\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m interpreter\u001B[38;5;241m.\u001B[39minvoke()\n\u001B[1;32m     36\u001B[0m output_data \u001B[38;5;241m=\u001B[39m interpreter\u001B[38;5;241m.\u001B[39mget_tensor(output_details[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[0;32m~/miniconda3/envs/CompositeADLRecognition/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:732\u001B[0m, in \u001B[0;36mInterpreter.set_tensor\u001B[0;34m(self, tensor_index, value)\u001B[0m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_tensor\u001B[39m(\u001B[38;5;28mself\u001B[39m, tensor_index, value):\n\u001B[1;32m    717\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Sets the value of the input tensor.\u001B[39;00m\n\u001B[1;32m    718\u001B[0m \n\u001B[1;32m    719\u001B[0m \u001B[38;5;124;03m  Note this copies data in `value`.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    730\u001B[0m \u001B[38;5;124;03m    ValueError: If the interpreter could not set the tensor.\u001B[39;00m\n\u001B[1;32m    731\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 732\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpreter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSetTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 0."
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "addeaa0e8bcc4125"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
