{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-27T00:39:18.921740Z",
     "start_time": "2024-09-27T00:34:46.329494Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Load the preprocessed data\n",
    "X_train = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/X_train.txt\")\n",
    "y_train = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/y_train.txt\")\n",
    "X_test = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/X_test.txt\")\n",
    "y_test = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/y_test.txt\")\n",
    "\n",
    "# Reshape the input data for Conv1D layers\n",
    "n_timestep = 100\n",
    "n_features = 9\n",
    "X_train = X_train.reshape(X_train.shape[0], n_timestep, n_features)\n",
    "X_test = X_test.reshape(X_test.shape[0], n_timestep, n_features)\n",
    "\n",
    "# One-hot encode the labels\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)\n",
    "\n",
    "def create_model(n_timesteps, n_features, n_outputs):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation=\"relu\", input_shape=(n_timesteps, n_features)),\n",
    "        Conv1D(filters=64, kernel_size=3, activation=\"relu\"),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(n_outputs, activation=\"softmax\")\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "n_outputs = y_train.shape[1]\n",
    "conv_mlp = create_model(n_timestep, n_features, n_outputs)\n",
    "conv_mlp.compile(optimizer=Adam(learning_rate=0.001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = conv_mlp.fit(X_train, y_train, epochs=500, batch_size=512, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = conv_mlp.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true_classes, y_pred_classes, digits=5))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denuvo-drm/miniconda3/envs/CompositeADLRecognition/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 15ms/step - accuracy: 0.2590 - loss: 2.3499 - val_accuracy: 0.6036 - val_loss: 1.2346\n",
      "Epoch 2/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.6355 - loss: 1.1177 - val_accuracy: 0.6735 - val_loss: 1.0234\n",
      "Epoch 3/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7203 - loss: 0.8588 - val_accuracy: 0.7043 - val_loss: 0.9290\n",
      "Epoch 4/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7581 - loss: 0.7475 - val_accuracy: 0.7162 - val_loss: 0.9354\n",
      "Epoch 5/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7790 - loss: 0.6776 - val_accuracy: 0.7164 - val_loss: 0.9329\n",
      "Epoch 6/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7944 - loss: 0.6294 - val_accuracy: 0.7443 - val_loss: 0.8891\n",
      "Epoch 7/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8080 - loss: 0.5873 - val_accuracy: 0.7228 - val_loss: 0.9326\n",
      "Epoch 8/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8205 - loss: 0.5510 - val_accuracy: 0.7445 - val_loss: 0.9179\n",
      "Epoch 9/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8304 - loss: 0.5211 - val_accuracy: 0.7362 - val_loss: 0.9678\n",
      "Epoch 10/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8330 - loss: 0.5029 - val_accuracy: 0.7563 - val_loss: 0.8791\n",
      "Epoch 11/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8438 - loss: 0.4806 - val_accuracy: 0.7583 - val_loss: 0.9010\n",
      "Epoch 12/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8505 - loss: 0.4549 - val_accuracy: 0.7512 - val_loss: 0.9410\n",
      "Epoch 13/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8508 - loss: 0.4538 - val_accuracy: 0.7541 - val_loss: 0.9357\n",
      "Epoch 14/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8587 - loss: 0.4281 - val_accuracy: 0.7555 - val_loss: 0.9830\n",
      "Epoch 15/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8646 - loss: 0.4137 - val_accuracy: 0.7494 - val_loss: 0.9860\n",
      "Epoch 16/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.8655 - loss: 0.4065 - val_accuracy: 0.7530 - val_loss: 0.9877\n",
      "Epoch 17/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8705 - loss: 0.3962 - val_accuracy: 0.7516 - val_loss: 0.9464\n",
      "Epoch 18/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8734 - loss: 0.3883 - val_accuracy: 0.7534 - val_loss: 0.9711\n",
      "Epoch 19/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8779 - loss: 0.3746 - val_accuracy: 0.7605 - val_loss: 0.9526\n",
      "Epoch 20/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8786 - loss: 0.3712 - val_accuracy: 0.7572 - val_loss: 0.9885\n",
      "Epoch 21/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8793 - loss: 0.3657 - val_accuracy: 0.7650 - val_loss: 1.0187\n",
      "Epoch 22/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8866 - loss: 0.3512 - val_accuracy: 0.7623 - val_loss: 1.0309\n",
      "Epoch 23/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8851 - loss: 0.3547 - val_accuracy: 0.7590 - val_loss: 1.0398\n",
      "Epoch 24/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8893 - loss: 0.3417 - val_accuracy: 0.7654 - val_loss: 1.0317\n",
      "Epoch 25/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8893 - loss: 0.3346 - val_accuracy: 0.7580 - val_loss: 1.0476\n",
      "Epoch 26/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8920 - loss: 0.3311 - val_accuracy: 0.7637 - val_loss: 0.9923\n",
      "Epoch 27/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8918 - loss: 0.3225 - val_accuracy: 0.7675 - val_loss: 1.0662\n",
      "Epoch 28/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8967 - loss: 0.3144 - val_accuracy: 0.7688 - val_loss: 1.0252\n",
      "Epoch 29/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.8980 - loss: 0.3129 - val_accuracy: 0.7615 - val_loss: 1.0735\n",
      "Epoch 30/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9025 - loss: 0.2993 - val_accuracy: 0.7722 - val_loss: 1.0564\n",
      "Epoch 31/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9001 - loss: 0.2997 - val_accuracy: 0.7597 - val_loss: 1.0985\n",
      "Epoch 32/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9030 - loss: 0.2981 - val_accuracy: 0.7703 - val_loss: 1.0943\n",
      "Epoch 33/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9034 - loss: 0.2906 - val_accuracy: 0.7680 - val_loss: 1.0946\n",
      "Epoch 34/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9041 - loss: 0.2940 - val_accuracy: 0.7644 - val_loss: 1.1051\n",
      "Epoch 35/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9073 - loss: 0.2852 - val_accuracy: 0.7645 - val_loss: 1.1276\n",
      "Epoch 36/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9090 - loss: 0.2786 - val_accuracy: 0.7735 - val_loss: 1.1175\n",
      "Epoch 37/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9086 - loss: 0.2786 - val_accuracy: 0.7632 - val_loss: 1.1542\n",
      "Epoch 38/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9118 - loss: 0.2700 - val_accuracy: 0.7667 - val_loss: 1.1156\n",
      "Epoch 39/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9105 - loss: 0.2730 - val_accuracy: 0.7550 - val_loss: 1.2638\n",
      "Epoch 40/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9104 - loss: 0.2714 - val_accuracy: 0.7648 - val_loss: 1.1493\n",
      "Epoch 41/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9123 - loss: 0.2697 - val_accuracy: 0.7762 - val_loss: 1.0950\n",
      "Epoch 42/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9122 - loss: 0.2668 - val_accuracy: 0.7675 - val_loss: 1.1985\n",
      "Epoch 43/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9173 - loss: 0.2531 - val_accuracy: 0.7649 - val_loss: 1.1800\n",
      "Epoch 44/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9160 - loss: 0.2574 - val_accuracy: 0.7626 - val_loss: 1.1819\n",
      "Epoch 45/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9160 - loss: 0.2551 - val_accuracy: 0.7637 - val_loss: 1.2169\n",
      "Epoch 46/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9185 - loss: 0.2472 - val_accuracy: 0.7710 - val_loss: 1.1650\n",
      "Epoch 47/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9177 - loss: 0.2487 - val_accuracy: 0.7798 - val_loss: 1.2257\n",
      "Epoch 48/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9180 - loss: 0.2491 - val_accuracy: 0.7790 - val_loss: 1.1570\n",
      "Epoch 49/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9220 - loss: 0.2379 - val_accuracy: 0.7657 - val_loss: 1.1509\n",
      "Epoch 50/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9175 - loss: 0.2494 - val_accuracy: 0.7661 - val_loss: 1.1905\n",
      "Epoch 51/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9211 - loss: 0.2379 - val_accuracy: 0.7643 - val_loss: 1.1472\n",
      "Epoch 52/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9223 - loss: 0.2374 - val_accuracy: 0.7568 - val_loss: 1.2776\n",
      "Epoch 53/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9232 - loss: 0.2345 - val_accuracy: 0.7556 - val_loss: 1.2196\n",
      "Epoch 54/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9203 - loss: 0.2379 - val_accuracy: 0.7778 - val_loss: 1.1611\n",
      "Epoch 55/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9229 - loss: 0.2306 - val_accuracy: 0.7771 - val_loss: 1.1701\n",
      "Epoch 56/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9246 - loss: 0.2312 - val_accuracy: 0.7696 - val_loss: 1.2422\n",
      "Epoch 57/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9277 - loss: 0.2246 - val_accuracy: 0.7616 - val_loss: 1.2645\n",
      "Epoch 58/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9259 - loss: 0.2240 - val_accuracy: 0.7604 - val_loss: 1.2780\n",
      "Epoch 59/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9270 - loss: 0.2239 - val_accuracy: 0.7511 - val_loss: 1.2578\n",
      "Epoch 60/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9255 - loss: 0.2230 - val_accuracy: 0.7674 - val_loss: 1.2523\n",
      "Epoch 61/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9257 - loss: 0.2215 - val_accuracy: 0.7648 - val_loss: 1.2730\n",
      "Epoch 62/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9269 - loss: 0.2167 - val_accuracy: 0.7679 - val_loss: 1.1719\n",
      "Epoch 63/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9284 - loss: 0.2152 - val_accuracy: 0.7513 - val_loss: 1.3424\n",
      "Epoch 64/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9276 - loss: 0.2185 - val_accuracy: 0.7659 - val_loss: 1.2549\n",
      "Epoch 65/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9303 - loss: 0.2133 - val_accuracy: 0.7642 - val_loss: 1.1684\n",
      "Epoch 66/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9281 - loss: 0.2166 - val_accuracy: 0.7588 - val_loss: 1.2299\n",
      "Epoch 67/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9299 - loss: 0.2140 - val_accuracy: 0.7627 - val_loss: 1.3032\n",
      "Epoch 68/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9300 - loss: 0.2143 - val_accuracy: 0.7654 - val_loss: 1.2651\n",
      "Epoch 69/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9314 - loss: 0.2076 - val_accuracy: 0.7688 - val_loss: 1.2495\n",
      "Epoch 70/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9293 - loss: 0.2111 - val_accuracy: 0.7643 - val_loss: 1.2385\n",
      "Epoch 71/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9326 - loss: 0.2028 - val_accuracy: 0.7794 - val_loss: 1.2883\n",
      "Epoch 72/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9322 - loss: 0.2086 - val_accuracy: 0.7675 - val_loss: 1.2361\n",
      "Epoch 73/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9335 - loss: 0.2032 - val_accuracy: 0.7734 - val_loss: 1.2691\n",
      "Epoch 74/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9313 - loss: 0.2037 - val_accuracy: 0.7686 - val_loss: 1.3073\n",
      "Epoch 75/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9337 - loss: 0.2009 - val_accuracy: 0.7716 - val_loss: 1.2658\n",
      "Epoch 76/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9350 - loss: 0.1960 - val_accuracy: 0.7665 - val_loss: 1.2696\n",
      "Epoch 77/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9337 - loss: 0.1991 - val_accuracy: 0.7647 - val_loss: 1.3529\n",
      "Epoch 78/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9343 - loss: 0.1977 - val_accuracy: 0.7540 - val_loss: 1.3233\n",
      "Epoch 79/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9333 - loss: 0.1964 - val_accuracy: 0.7657 - val_loss: 1.3056\n",
      "Epoch 80/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9370 - loss: 0.1932 - val_accuracy: 0.7606 - val_loss: 1.3629\n",
      "Epoch 81/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9346 - loss: 0.1930 - val_accuracy: 0.7668 - val_loss: 1.3021\n",
      "Epoch 82/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9367 - loss: 0.1905 - val_accuracy: 0.7713 - val_loss: 1.2842\n",
      "Epoch 83/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9362 - loss: 0.1931 - val_accuracy: 0.7701 - val_loss: 1.3032\n",
      "Epoch 84/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9355 - loss: 0.1931 - val_accuracy: 0.7739 - val_loss: 1.2349\n",
      "Epoch 85/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9371 - loss: 0.1866 - val_accuracy: 0.7599 - val_loss: 1.3549\n",
      "Epoch 86/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9373 - loss: 0.1876 - val_accuracy: 0.7695 - val_loss: 1.2462\n",
      "Epoch 87/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9353 - loss: 0.1940 - val_accuracy: 0.7675 - val_loss: 1.3855\n",
      "Epoch 88/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9380 - loss: 0.1894 - val_accuracy: 0.7705 - val_loss: 1.2702\n",
      "Epoch 89/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9371 - loss: 0.1881 - val_accuracy: 0.7778 - val_loss: 1.3299\n",
      "Epoch 90/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9401 - loss: 0.1836 - val_accuracy: 0.7655 - val_loss: 1.2748\n",
      "Epoch 91/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9401 - loss: 0.1811 - val_accuracy: 0.7669 - val_loss: 1.3449\n",
      "Epoch 92/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9395 - loss: 0.1821 - val_accuracy: 0.7691 - val_loss: 1.3036\n",
      "Epoch 93/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9393 - loss: 0.1827 - val_accuracy: 0.7701 - val_loss: 1.2721\n",
      "Epoch 94/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9381 - loss: 0.1814 - val_accuracy: 0.7659 - val_loss: 1.3138\n",
      "Epoch 95/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9397 - loss: 0.1816 - val_accuracy: 0.7766 - val_loss: 1.2720\n",
      "Epoch 96/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9383 - loss: 0.1811 - val_accuracy: 0.7637 - val_loss: 1.3790\n",
      "Epoch 97/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9396 - loss: 0.1794 - val_accuracy: 0.7613 - val_loss: 1.3686\n",
      "Epoch 98/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9424 - loss: 0.1750 - val_accuracy: 0.7599 - val_loss: 1.3210\n",
      "Epoch 99/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9404 - loss: 0.1768 - val_accuracy: 0.7682 - val_loss: 1.3591\n",
      "Epoch 100/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9416 - loss: 0.1738 - val_accuracy: 0.7769 - val_loss: 1.3056\n",
      "Epoch 101/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9395 - loss: 0.1780 - val_accuracy: 0.7768 - val_loss: 1.3185\n",
      "Epoch 102/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9427 - loss: 0.1713 - val_accuracy: 0.7656 - val_loss: 1.3965\n",
      "Epoch 103/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9427 - loss: 0.1744 - val_accuracy: 0.7621 - val_loss: 1.3163\n",
      "Epoch 104/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9422 - loss: 0.1757 - val_accuracy: 0.7666 - val_loss: 1.4061\n",
      "Epoch 105/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9432 - loss: 0.1689 - val_accuracy: 0.7779 - val_loss: 1.3568\n",
      "Epoch 106/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9452 - loss: 0.1669 - val_accuracy: 0.7684 - val_loss: 1.4415\n",
      "Epoch 107/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9425 - loss: 0.1712 - val_accuracy: 0.7703 - val_loss: 1.4003\n",
      "Epoch 108/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9432 - loss: 0.1704 - val_accuracy: 0.7753 - val_loss: 1.3910\n",
      "Epoch 109/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9430 - loss: 0.1676 - val_accuracy: 0.7786 - val_loss: 1.3156\n",
      "Epoch 110/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9443 - loss: 0.1651 - val_accuracy: 0.7639 - val_loss: 1.3324\n",
      "Epoch 111/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9443 - loss: 0.1665 - val_accuracy: 0.7688 - val_loss: 1.4233\n",
      "Epoch 112/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9451 - loss: 0.1660 - val_accuracy: 0.7553 - val_loss: 1.4367\n",
      "Epoch 113/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9444 - loss: 0.1693 - val_accuracy: 0.7578 - val_loss: 1.3498\n",
      "Epoch 114/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9452 - loss: 0.1648 - val_accuracy: 0.7698 - val_loss: 1.3557\n",
      "Epoch 115/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9458 - loss: 0.1651 - val_accuracy: 0.7713 - val_loss: 1.4061\n",
      "Epoch 116/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9436 - loss: 0.1679 - val_accuracy: 0.7648 - val_loss: 1.4597\n",
      "Epoch 117/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9452 - loss: 0.1620 - val_accuracy: 0.7747 - val_loss: 1.3846\n",
      "Epoch 118/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9464 - loss: 0.1607 - val_accuracy: 0.7724 - val_loss: 1.3365\n",
      "Epoch 119/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9469 - loss: 0.1596 - val_accuracy: 0.7633 - val_loss: 1.4016\n",
      "Epoch 120/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9459 - loss: 0.1600 - val_accuracy: 0.7665 - val_loss: 1.3654\n",
      "Epoch 121/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9450 - loss: 0.1599 - val_accuracy: 0.7745 - val_loss: 1.4561\n",
      "Epoch 122/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9456 - loss: 0.1616 - val_accuracy: 0.7737 - val_loss: 1.4515\n",
      "Epoch 123/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9456 - loss: 0.1607 - val_accuracy: 0.7679 - val_loss: 1.4282\n",
      "Epoch 124/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9486 - loss: 0.1544 - val_accuracy: 0.7665 - val_loss: 1.3346\n",
      "Epoch 125/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9480 - loss: 0.1556 - val_accuracy: 0.7706 - val_loss: 1.4809\n",
      "Epoch 126/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9457 - loss: 0.1608 - val_accuracy: 0.7830 - val_loss: 1.4277\n",
      "Epoch 127/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9490 - loss: 0.1534 - val_accuracy: 0.7657 - val_loss: 1.3782\n",
      "Epoch 128/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9459 - loss: 0.1619 - val_accuracy: 0.7701 - val_loss: 1.3861\n",
      "Epoch 129/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9475 - loss: 0.1541 - val_accuracy: 0.7667 - val_loss: 1.4564\n",
      "Epoch 130/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9464 - loss: 0.1604 - val_accuracy: 0.7740 - val_loss: 1.4022\n",
      "Epoch 131/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9462 - loss: 0.1609 - val_accuracy: 0.7691 - val_loss: 1.4622\n",
      "Epoch 132/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9488 - loss: 0.1517 - val_accuracy: 0.7706 - val_loss: 1.3991\n",
      "Epoch 133/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9495 - loss: 0.1519 - val_accuracy: 0.7839 - val_loss: 1.3759\n",
      "Epoch 134/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9474 - loss: 0.1578 - val_accuracy: 0.7807 - val_loss: 1.4013\n",
      "Epoch 135/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9490 - loss: 0.1512 - val_accuracy: 0.7796 - val_loss: 1.4136\n",
      "Epoch 136/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9480 - loss: 0.1527 - val_accuracy: 0.7755 - val_loss: 1.3917\n",
      "Epoch 137/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9476 - loss: 0.1566 - val_accuracy: 0.7743 - val_loss: 1.4629\n",
      "Epoch 138/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9493 - loss: 0.1520 - val_accuracy: 0.7773 - val_loss: 1.4040\n",
      "Epoch 139/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9491 - loss: 0.1538 - val_accuracy: 0.7775 - val_loss: 1.4755\n",
      "Epoch 140/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.9487 - loss: 0.1510 - val_accuracy: 0.7812 - val_loss: 1.4396\n",
      "Epoch 141/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9496 - loss: 0.1509 - val_accuracy: 0.7736 - val_loss: 1.4637\n",
      "Epoch 142/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9506 - loss: 0.1468 - val_accuracy: 0.7615 - val_loss: 1.6057\n",
      "Epoch 143/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9515 - loss: 0.1496 - val_accuracy: 0.7752 - val_loss: 1.4284\n",
      "Epoch 144/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9489 - loss: 0.1527 - val_accuracy: 0.7739 - val_loss: 1.4904\n",
      "Epoch 145/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9504 - loss: 0.1475 - val_accuracy: 0.7752 - val_loss: 1.4539\n",
      "Epoch 146/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9496 - loss: 0.1496 - val_accuracy: 0.7795 - val_loss: 1.4207\n",
      "Epoch 147/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9491 - loss: 0.1529 - val_accuracy: 0.7825 - val_loss: 1.4790\n",
      "Epoch 148/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9505 - loss: 0.1477 - val_accuracy: 0.7750 - val_loss: 1.4195\n",
      "Epoch 149/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9520 - loss: 0.1440 - val_accuracy: 0.7812 - val_loss: 1.5245\n",
      "Epoch 150/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9508 - loss: 0.1463 - val_accuracy: 0.7705 - val_loss: 1.5119\n",
      "Epoch 151/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9492 - loss: 0.1520 - val_accuracy: 0.7720 - val_loss: 1.5083\n",
      "Epoch 152/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9515 - loss: 0.1441 - val_accuracy: 0.7707 - val_loss: 1.5290\n",
      "Epoch 153/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9484 - loss: 0.1529 - val_accuracy: 0.7701 - val_loss: 1.4500\n",
      "Epoch 154/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9515 - loss: 0.1438 - val_accuracy: 0.7635 - val_loss: 1.4811\n",
      "Epoch 155/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9494 - loss: 0.1499 - val_accuracy: 0.7799 - val_loss: 1.3906\n",
      "Epoch 156/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9498 - loss: 0.1480 - val_accuracy: 0.7763 - val_loss: 1.4871\n",
      "Epoch 157/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9526 - loss: 0.1410 - val_accuracy: 0.7740 - val_loss: 1.5459\n",
      "Epoch 158/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9520 - loss: 0.1446 - val_accuracy: 0.7739 - val_loss: 1.5629\n",
      "Epoch 159/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9504 - loss: 0.1488 - val_accuracy: 0.7763 - val_loss: 1.4602\n",
      "Epoch 160/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9498 - loss: 0.1501 - val_accuracy: 0.7730 - val_loss: 1.4739\n",
      "Epoch 161/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9513 - loss: 0.1461 - val_accuracy: 0.7700 - val_loss: 1.5814\n",
      "Epoch 162/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9508 - loss: 0.1464 - val_accuracy: 0.7792 - val_loss: 1.4153\n",
      "Epoch 163/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9520 - loss: 0.1392 - val_accuracy: 0.7727 - val_loss: 1.5522\n",
      "Epoch 164/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9505 - loss: 0.1490 - val_accuracy: 0.7814 - val_loss: 1.4155\n",
      "Epoch 165/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9501 - loss: 0.1473 - val_accuracy: 0.7740 - val_loss: 1.5239\n",
      "Epoch 166/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9515 - loss: 0.1444 - val_accuracy: 0.7860 - val_loss: 1.4334\n",
      "Epoch 167/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9519 - loss: 0.1416 - val_accuracy: 0.7717 - val_loss: 1.5468\n",
      "Epoch 168/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9515 - loss: 0.1414 - val_accuracy: 0.7846 - val_loss: 1.4684\n",
      "Epoch 169/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9549 - loss: 0.1388 - val_accuracy: 0.7739 - val_loss: 1.4713\n",
      "Epoch 170/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9515 - loss: 0.1430 - val_accuracy: 0.7785 - val_loss: 1.5398\n",
      "Epoch 171/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9530 - loss: 0.1434 - val_accuracy: 0.7774 - val_loss: 1.4803\n",
      "Epoch 172/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9505 - loss: 0.1425 - val_accuracy: 0.7813 - val_loss: 1.3887\n",
      "Epoch 173/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9504 - loss: 0.1446 - val_accuracy: 0.7776 - val_loss: 1.5001\n",
      "Epoch 174/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9523 - loss: 0.1397 - val_accuracy: 0.7778 - val_loss: 1.6080\n",
      "Epoch 175/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9539 - loss: 0.1362 - val_accuracy: 0.7758 - val_loss: 1.5068\n",
      "Epoch 176/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9525 - loss: 0.1391 - val_accuracy: 0.7782 - val_loss: 1.5244\n",
      "Epoch 177/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9529 - loss: 0.1380 - val_accuracy: 0.7860 - val_loss: 1.5138\n",
      "Epoch 178/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9541 - loss: 0.1358 - val_accuracy: 0.7754 - val_loss: 1.5449\n",
      "Epoch 179/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9541 - loss: 0.1356 - val_accuracy: 0.7757 - val_loss: 1.5399\n",
      "Epoch 180/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9510 - loss: 0.1417 - val_accuracy: 0.7701 - val_loss: 1.5569\n",
      "Epoch 181/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9529 - loss: 0.1387 - val_accuracy: 0.7751 - val_loss: 1.5888\n",
      "Epoch 182/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9557 - loss: 0.1324 - val_accuracy: 0.7777 - val_loss: 1.6133\n",
      "Epoch 183/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9529 - loss: 0.1408 - val_accuracy: 0.7681 - val_loss: 1.6204\n",
      "Epoch 184/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9533 - loss: 0.1389 - val_accuracy: 0.7761 - val_loss: 1.5293\n",
      "Epoch 185/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9548 - loss: 0.1359 - val_accuracy: 0.7746 - val_loss: 1.5616\n",
      "Epoch 186/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9527 - loss: 0.1382 - val_accuracy: 0.7739 - val_loss: 1.5694\n",
      "Epoch 187/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9559 - loss: 0.1315 - val_accuracy: 0.7615 - val_loss: 1.5070\n",
      "Epoch 188/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9543 - loss: 0.1373 - val_accuracy: 0.7693 - val_loss: 1.5457\n",
      "Epoch 189/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9565 - loss: 0.1303 - val_accuracy: 0.7829 - val_loss: 1.5288\n",
      "Epoch 190/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9554 - loss: 0.1331 - val_accuracy: 0.7655 - val_loss: 1.6200\n",
      "Epoch 191/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9531 - loss: 0.1364 - val_accuracy: 0.7838 - val_loss: 1.5459\n",
      "Epoch 192/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9556 - loss: 0.1321 - val_accuracy: 0.7699 - val_loss: 1.5641\n",
      "Epoch 193/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9553 - loss: 0.1294 - val_accuracy: 0.7775 - val_loss: 1.6921\n",
      "Epoch 194/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9551 - loss: 0.1312 - val_accuracy: 0.7815 - val_loss: 1.5504\n",
      "Epoch 195/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9536 - loss: 0.1340 - val_accuracy: 0.7826 - val_loss: 1.5358\n",
      "Epoch 196/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9551 - loss: 0.1308 - val_accuracy: 0.7775 - val_loss: 1.5808\n",
      "Epoch 197/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9554 - loss: 0.1318 - val_accuracy: 0.7712 - val_loss: 1.5573\n",
      "Epoch 198/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9554 - loss: 0.1304 - val_accuracy: 0.7832 - val_loss: 1.5488\n",
      "Epoch 199/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9550 - loss: 0.1347 - val_accuracy: 0.7808 - val_loss: 1.4663\n",
      "Epoch 200/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9575 - loss: 0.1252 - val_accuracy: 0.7794 - val_loss: 1.5318\n",
      "Epoch 201/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9562 - loss: 0.1307 - val_accuracy: 0.7792 - val_loss: 1.5185\n",
      "Epoch 202/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9558 - loss: 0.1316 - val_accuracy: 0.7750 - val_loss: 1.6384\n",
      "Epoch 203/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9563 - loss: 0.1302 - val_accuracy: 0.7695 - val_loss: 1.6044\n",
      "Epoch 204/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9547 - loss: 0.1320 - val_accuracy: 0.7810 - val_loss: 1.5241\n",
      "Epoch 205/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9561 - loss: 0.1301 - val_accuracy: 0.7788 - val_loss: 1.5170\n",
      "Epoch 206/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9543 - loss: 0.1307 - val_accuracy: 0.7682 - val_loss: 1.5451\n",
      "Epoch 207/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9556 - loss: 0.1277 - val_accuracy: 0.7802 - val_loss: 1.5246\n",
      "Epoch 208/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9572 - loss: 0.1285 - val_accuracy: 0.7845 - val_loss: 1.6205\n",
      "Epoch 209/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9569 - loss: 0.1279 - val_accuracy: 0.7744 - val_loss: 1.5750\n",
      "Epoch 210/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9574 - loss: 0.1257 - val_accuracy: 0.7785 - val_loss: 1.5512\n",
      "Epoch 211/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9564 - loss: 0.1281 - val_accuracy: 0.7667 - val_loss: 1.5514\n",
      "Epoch 212/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9552 - loss: 0.1301 - val_accuracy: 0.7835 - val_loss: 1.6815\n",
      "Epoch 213/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9560 - loss: 0.1263 - val_accuracy: 0.7803 - val_loss: 1.6944\n",
      "Epoch 214/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9554 - loss: 0.1267 - val_accuracy: 0.7752 - val_loss: 1.5560\n",
      "Epoch 215/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9559 - loss: 0.1285 - val_accuracy: 0.7793 - val_loss: 1.5902\n",
      "Epoch 216/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9564 - loss: 0.1292 - val_accuracy: 0.7818 - val_loss: 1.5794\n",
      "Epoch 217/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9565 - loss: 0.1271 - val_accuracy: 0.7768 - val_loss: 1.6082\n",
      "Epoch 218/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9542 - loss: 0.1321 - val_accuracy: 0.7843 - val_loss: 1.6090\n",
      "Epoch 219/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9571 - loss: 0.1278 - val_accuracy: 0.7863 - val_loss: 1.6756\n",
      "Epoch 220/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9559 - loss: 0.1287 - val_accuracy: 0.7816 - val_loss: 1.5690\n",
      "Epoch 221/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9575 - loss: 0.1238 - val_accuracy: 0.7815 - val_loss: 1.5733\n",
      "Epoch 222/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9559 - loss: 0.1257 - val_accuracy: 0.7866 - val_loss: 1.5260\n",
      "Epoch 223/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9583 - loss: 0.1242 - val_accuracy: 0.7838 - val_loss: 1.6441\n",
      "Epoch 224/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9569 - loss: 0.1290 - val_accuracy: 0.7741 - val_loss: 1.7445\n",
      "Epoch 225/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9568 - loss: 0.1264 - val_accuracy: 0.7819 - val_loss: 1.5977\n",
      "Epoch 226/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9566 - loss: 0.1268 - val_accuracy: 0.7807 - val_loss: 1.6279\n",
      "Epoch 227/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9573 - loss: 0.1267 - val_accuracy: 0.7791 - val_loss: 1.6136\n",
      "Epoch 228/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9571 - loss: 0.1241 - val_accuracy: 0.7752 - val_loss: 1.6742\n",
      "Epoch 229/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9577 - loss: 0.1219 - val_accuracy: 0.7830 - val_loss: 1.6746\n",
      "Epoch 230/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9571 - loss: 0.1260 - val_accuracy: 0.7755 - val_loss: 1.5755\n",
      "Epoch 231/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9563 - loss: 0.1285 - val_accuracy: 0.7790 - val_loss: 1.5707\n",
      "Epoch 232/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9579 - loss: 0.1245 - val_accuracy: 0.7836 - val_loss: 1.5669\n",
      "Epoch 233/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9575 - loss: 0.1277 - val_accuracy: 0.7735 - val_loss: 1.6558\n",
      "Epoch 234/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9576 - loss: 0.1247 - val_accuracy: 0.7802 - val_loss: 1.5733\n",
      "Epoch 235/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9576 - loss: 0.1221 - val_accuracy: 0.7723 - val_loss: 1.6021\n",
      "Epoch 236/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9596 - loss: 0.1213 - val_accuracy: 0.7774 - val_loss: 1.6191\n",
      "Epoch 237/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9582 - loss: 0.1216 - val_accuracy: 0.7757 - val_loss: 1.6747\n",
      "Epoch 238/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9580 - loss: 0.1238 - val_accuracy: 0.7787 - val_loss: 1.6681\n",
      "Epoch 239/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9576 - loss: 0.1247 - val_accuracy: 0.7789 - val_loss: 1.5512\n",
      "Epoch 240/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9579 - loss: 0.1216 - val_accuracy: 0.7766 - val_loss: 1.6981\n",
      "Epoch 241/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9567 - loss: 0.1223 - val_accuracy: 0.7726 - val_loss: 1.7176\n",
      "Epoch 242/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9588 - loss: 0.1191 - val_accuracy: 0.7791 - val_loss: 1.5918\n",
      "Epoch 243/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9596 - loss: 0.1188 - val_accuracy: 0.7821 - val_loss: 1.6569\n",
      "Epoch 244/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9574 - loss: 0.1240 - val_accuracy: 0.7796 - val_loss: 1.6563\n",
      "Epoch 245/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9590 - loss: 0.1197 - val_accuracy: 0.7813 - val_loss: 1.6847\n",
      "Epoch 246/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9586 - loss: 0.1221 - val_accuracy: 0.7848 - val_loss: 1.6298\n",
      "Epoch 247/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9580 - loss: 0.1225 - val_accuracy: 0.7801 - val_loss: 1.6569\n",
      "Epoch 248/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9585 - loss: 0.1220 - val_accuracy: 0.7779 - val_loss: 1.5994\n",
      "Epoch 249/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9586 - loss: 0.1212 - val_accuracy: 0.7767 - val_loss: 1.7209\n",
      "Epoch 250/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9591 - loss: 0.1212 - val_accuracy: 0.7767 - val_loss: 1.7195\n",
      "Epoch 251/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9596 - loss: 0.1189 - val_accuracy: 0.7659 - val_loss: 1.6675\n",
      "Epoch 252/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9581 - loss: 0.1238 - val_accuracy: 0.7786 - val_loss: 1.6860\n",
      "Epoch 253/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9602 - loss: 0.1160 - val_accuracy: 0.7857 - val_loss: 1.6515\n",
      "Epoch 254/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9590 - loss: 0.1204 - val_accuracy: 0.7773 - val_loss: 1.6520\n",
      "Epoch 255/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9599 - loss: 0.1178 - val_accuracy: 0.7774 - val_loss: 1.7112\n",
      "Epoch 256/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9613 - loss: 0.1177 - val_accuracy: 0.7726 - val_loss: 1.5920\n",
      "Epoch 257/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9570 - loss: 0.1254 - val_accuracy: 0.7775 - val_loss: 1.6331\n",
      "Epoch 258/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9601 - loss: 0.1144 - val_accuracy: 0.7740 - val_loss: 1.6638\n",
      "Epoch 259/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9603 - loss: 0.1183 - val_accuracy: 0.7759 - val_loss: 1.6867\n",
      "Epoch 260/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9613 - loss: 0.1148 - val_accuracy: 0.7806 - val_loss: 1.6850\n",
      "Epoch 261/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9592 - loss: 0.1173 - val_accuracy: 0.7803 - val_loss: 1.5992\n",
      "Epoch 262/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9590 - loss: 0.1184 - val_accuracy: 0.7798 - val_loss: 1.5936\n",
      "Epoch 263/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9581 - loss: 0.1218 - val_accuracy: 0.7752 - val_loss: 1.7209\n",
      "Epoch 264/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9601 - loss: 0.1187 - val_accuracy: 0.7818 - val_loss: 1.5971\n",
      "Epoch 265/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9576 - loss: 0.1222 - val_accuracy: 0.7647 - val_loss: 1.7525\n",
      "Epoch 266/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9617 - loss: 0.1140 - val_accuracy: 0.7745 - val_loss: 1.6818\n",
      "Epoch 267/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9591 - loss: 0.1181 - val_accuracy: 0.7767 - val_loss: 1.7286\n",
      "Epoch 268/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9606 - loss: 0.1164 - val_accuracy: 0.7846 - val_loss: 1.5803\n",
      "Epoch 269/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9595 - loss: 0.1178 - val_accuracy: 0.7783 - val_loss: 1.7825\n",
      "Epoch 270/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9602 - loss: 0.1183 - val_accuracy: 0.7819 - val_loss: 1.6297\n",
      "Epoch 271/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9601 - loss: 0.1183 - val_accuracy: 0.7798 - val_loss: 1.6849\n",
      "Epoch 272/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9601 - loss: 0.1202 - val_accuracy: 0.7767 - val_loss: 1.6090\n",
      "Epoch 273/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9594 - loss: 0.1204 - val_accuracy: 0.7762 - val_loss: 1.6590\n",
      "Epoch 274/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9617 - loss: 0.1120 - val_accuracy: 0.7809 - val_loss: 1.5606\n",
      "Epoch 275/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9591 - loss: 0.1185 - val_accuracy: 0.7809 - val_loss: 1.6472\n",
      "Epoch 276/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9607 - loss: 0.1144 - val_accuracy: 0.7822 - val_loss: 1.6103\n",
      "Epoch 277/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9613 - loss: 0.1127 - val_accuracy: 0.7774 - val_loss: 1.6664\n",
      "Epoch 278/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9610 - loss: 0.1140 - val_accuracy: 0.7797 - val_loss: 1.5483\n",
      "Epoch 279/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9608 - loss: 0.1124 - val_accuracy: 0.7864 - val_loss: 1.6147\n",
      "Epoch 280/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9603 - loss: 0.1153 - val_accuracy: 0.7765 - val_loss: 1.6367\n",
      "Epoch 281/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9611 - loss: 0.1132 - val_accuracy: 0.7820 - val_loss: 1.7653\n",
      "Epoch 282/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9600 - loss: 0.1186 - val_accuracy: 0.7815 - val_loss: 1.5913\n",
      "Epoch 283/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9606 - loss: 0.1143 - val_accuracy: 0.7820 - val_loss: 1.6781\n",
      "Epoch 284/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9610 - loss: 0.1146 - val_accuracy: 0.7775 - val_loss: 1.6444\n",
      "Epoch 285/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9620 - loss: 0.1114 - val_accuracy: 0.7801 - val_loss: 1.7835\n",
      "Epoch 286/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9606 - loss: 0.1165 - val_accuracy: 0.7781 - val_loss: 1.6841\n",
      "Epoch 287/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9608 - loss: 0.1152 - val_accuracy: 0.7803 - val_loss: 1.6379\n",
      "Epoch 288/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9614 - loss: 0.1124 - val_accuracy: 0.7798 - val_loss: 1.7395\n",
      "Epoch 289/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9617 - loss: 0.1131 - val_accuracy: 0.7806 - val_loss: 1.6819\n",
      "Epoch 290/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9604 - loss: 0.1143 - val_accuracy: 0.7793 - val_loss: 1.7280\n",
      "Epoch 291/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9599 - loss: 0.1183 - val_accuracy: 0.7806 - val_loss: 1.6932\n",
      "Epoch 292/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9615 - loss: 0.1122 - val_accuracy: 0.7799 - val_loss: 1.7105\n",
      "Epoch 293/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9611 - loss: 0.1106 - val_accuracy: 0.7728 - val_loss: 1.7144\n",
      "Epoch 294/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9611 - loss: 0.1136 - val_accuracy: 0.7769 - val_loss: 1.7628\n",
      "Epoch 295/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9631 - loss: 0.1088 - val_accuracy: 0.7769 - val_loss: 1.7535\n",
      "Epoch 296/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9624 - loss: 0.1110 - val_accuracy: 0.7738 - val_loss: 1.7416\n",
      "Epoch 297/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9625 - loss: 0.1106 - val_accuracy: 0.7805 - val_loss: 1.7716\n",
      "Epoch 298/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9611 - loss: 0.1144 - val_accuracy: 0.7774 - val_loss: 1.7395\n",
      "Epoch 299/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9621 - loss: 0.1131 - val_accuracy: 0.7786 - val_loss: 1.7229\n",
      "Epoch 300/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9623 - loss: 0.1122 - val_accuracy: 0.7780 - val_loss: 1.7357\n",
      "Epoch 301/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9619 - loss: 0.1117 - val_accuracy: 0.7819 - val_loss: 1.7929\n",
      "Epoch 302/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9598 - loss: 0.1153 - val_accuracy: 0.7874 - val_loss: 1.5640\n",
      "Epoch 303/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9625 - loss: 0.1077 - val_accuracy: 0.7781 - val_loss: 1.7805\n",
      "Epoch 304/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9615 - loss: 0.1138 - val_accuracy: 0.7772 - val_loss: 1.7651\n",
      "Epoch 305/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9628 - loss: 0.1096 - val_accuracy: 0.7833 - val_loss: 1.7729\n",
      "Epoch 306/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9624 - loss: 0.1081 - val_accuracy: 0.7717 - val_loss: 1.7072\n",
      "Epoch 307/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9610 - loss: 0.1122 - val_accuracy: 0.7779 - val_loss: 1.7642\n",
      "Epoch 308/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9628 - loss: 0.1092 - val_accuracy: 0.7761 - val_loss: 1.6572\n",
      "Epoch 309/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9597 - loss: 0.1139 - val_accuracy: 0.7846 - val_loss: 1.7048\n",
      "Epoch 310/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9625 - loss: 0.1087 - val_accuracy: 0.7792 - val_loss: 1.7116\n",
      "Epoch 311/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9610 - loss: 0.1128 - val_accuracy: 0.7862 - val_loss: 1.7432\n",
      "Epoch 312/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9631 - loss: 0.1069 - val_accuracy: 0.7758 - val_loss: 1.7993\n",
      "Epoch 313/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9612 - loss: 0.1127 - val_accuracy: 0.7828 - val_loss: 1.6866\n",
      "Epoch 314/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9625 - loss: 0.1101 - val_accuracy: 0.7807 - val_loss: 1.7686\n",
      "Epoch 315/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9634 - loss: 0.1077 - val_accuracy: 0.7755 - val_loss: 1.8345\n",
      "Epoch 316/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9623 - loss: 0.1101 - val_accuracy: 0.7775 - val_loss: 1.7517\n",
      "Epoch 317/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9618 - loss: 0.1116 - val_accuracy: 0.7645 - val_loss: 1.8399\n",
      "Epoch 318/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9617 - loss: 0.1103 - val_accuracy: 0.7674 - val_loss: 1.8385\n",
      "Epoch 319/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9626 - loss: 0.1084 - val_accuracy: 0.7679 - val_loss: 1.7679\n",
      "Epoch 320/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9627 - loss: 0.1087 - val_accuracy: 0.7745 - val_loss: 1.8117\n",
      "Epoch 321/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9632 - loss: 0.1084 - val_accuracy: 0.7711 - val_loss: 1.7361\n",
      "Epoch 322/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9639 - loss: 0.1103 - val_accuracy: 0.7750 - val_loss: 1.6973\n",
      "Epoch 323/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9616 - loss: 0.1076 - val_accuracy: 0.7666 - val_loss: 1.7949\n",
      "Epoch 324/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9615 - loss: 0.1137 - val_accuracy: 0.7836 - val_loss: 1.7217\n",
      "Epoch 325/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9604 - loss: 0.1093 - val_accuracy: 0.7817 - val_loss: 1.8067\n",
      "Epoch 326/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9615 - loss: 0.1114 - val_accuracy: 0.7760 - val_loss: 1.7105\n",
      "Epoch 327/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9625 - loss: 0.1111 - val_accuracy: 0.7790 - val_loss: 1.7546\n",
      "Epoch 328/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9651 - loss: 0.1024 - val_accuracy: 0.7812 - val_loss: 1.7591\n",
      "Epoch 329/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9639 - loss: 0.1029 - val_accuracy: 0.7863 - val_loss: 1.7378\n",
      "Epoch 330/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9630 - loss: 0.1068 - val_accuracy: 0.7721 - val_loss: 1.7549\n",
      "Epoch 331/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9625 - loss: 0.1096 - val_accuracy: 0.7783 - val_loss: 1.8787\n",
      "Epoch 332/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9636 - loss: 0.1024 - val_accuracy: 0.7766 - val_loss: 1.7028\n",
      "Epoch 333/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9622 - loss: 0.1079 - val_accuracy: 0.7749 - val_loss: 1.7531\n",
      "Epoch 334/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9629 - loss: 0.1075 - val_accuracy: 0.7743 - val_loss: 1.7987\n",
      "Epoch 335/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9654 - loss: 0.1018 - val_accuracy: 0.7784 - val_loss: 1.7151\n",
      "Epoch 336/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9632 - loss: 0.1076 - val_accuracy: 0.7804 - val_loss: 1.7506\n",
      "Epoch 337/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9638 - loss: 0.1052 - val_accuracy: 0.7758 - val_loss: 1.7910\n",
      "Epoch 338/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9650 - loss: 0.1021 - val_accuracy: 0.7742 - val_loss: 1.8074\n",
      "Epoch 339/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9622 - loss: 0.1095 - val_accuracy: 0.7735 - val_loss: 1.8089\n",
      "Epoch 340/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9638 - loss: 0.1065 - val_accuracy: 0.7816 - val_loss: 1.7711\n",
      "Epoch 341/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9640 - loss: 0.1037 - val_accuracy: 0.7892 - val_loss: 1.7542\n",
      "Epoch 342/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9627 - loss: 0.1077 - val_accuracy: 0.7814 - val_loss: 1.7635\n",
      "Epoch 343/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9626 - loss: 0.1101 - val_accuracy: 0.7709 - val_loss: 1.7584\n",
      "Epoch 344/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9635 - loss: 0.1084 - val_accuracy: 0.7789 - val_loss: 1.6930\n",
      "Epoch 345/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9644 - loss: 0.1059 - val_accuracy: 0.7761 - val_loss: 1.6942\n",
      "Epoch 346/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9652 - loss: 0.1005 - val_accuracy: 0.7786 - val_loss: 1.8440\n",
      "Epoch 347/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9624 - loss: 0.1078 - val_accuracy: 0.7833 - val_loss: 1.7256\n",
      "Epoch 348/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9635 - loss: 0.1062 - val_accuracy: 0.7726 - val_loss: 1.8016\n",
      "Epoch 349/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9624 - loss: 0.1091 - val_accuracy: 0.7738 - val_loss: 1.7188\n",
      "Epoch 350/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9646 - loss: 0.1034 - val_accuracy: 0.7787 - val_loss: 1.7612\n",
      "Epoch 351/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9630 - loss: 0.1093 - val_accuracy: 0.7812 - val_loss: 1.6706\n",
      "Epoch 352/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9634 - loss: 0.1062 - val_accuracy: 0.7798 - val_loss: 1.7115\n",
      "Epoch 353/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9652 - loss: 0.1014 - val_accuracy: 0.7750 - val_loss: 1.7163\n",
      "Epoch 354/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9635 - loss: 0.1036 - val_accuracy: 0.7800 - val_loss: 1.7689\n",
      "Epoch 355/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9648 - loss: 0.1008 - val_accuracy: 0.7793 - val_loss: 1.7982\n",
      "Epoch 356/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9651 - loss: 0.1023 - val_accuracy: 0.7764 - val_loss: 1.6738\n",
      "Epoch 357/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9630 - loss: 0.1071 - val_accuracy: 0.7826 - val_loss: 1.8457\n",
      "Epoch 358/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9634 - loss: 0.1026 - val_accuracy: 0.7821 - val_loss: 1.7253\n",
      "Epoch 359/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9651 - loss: 0.0992 - val_accuracy: 0.7771 - val_loss: 1.6796\n",
      "Epoch 360/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9622 - loss: 0.1082 - val_accuracy: 0.7843 - val_loss: 1.6954\n",
      "Epoch 361/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9637 - loss: 0.1064 - val_accuracy: 0.7827 - val_loss: 1.7039\n",
      "Epoch 362/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9645 - loss: 0.1004 - val_accuracy: 0.7752 - val_loss: 1.7409\n",
      "Epoch 363/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9654 - loss: 0.1010 - val_accuracy: 0.7801 - val_loss: 1.7190\n",
      "Epoch 364/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9649 - loss: 0.1030 - val_accuracy: 0.7669 - val_loss: 1.7616\n",
      "Epoch 365/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9639 - loss: 0.1066 - val_accuracy: 0.7769 - val_loss: 1.7897\n",
      "Epoch 366/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9634 - loss: 0.1029 - val_accuracy: 0.7736 - val_loss: 1.8004\n",
      "Epoch 367/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9635 - loss: 0.1058 - val_accuracy: 0.7725 - val_loss: 1.8268\n",
      "Epoch 368/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9646 - loss: 0.1020 - val_accuracy: 0.7807 - val_loss: 1.7263\n",
      "Epoch 369/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9649 - loss: 0.1013 - val_accuracy: 0.7728 - val_loss: 1.7927\n",
      "Epoch 370/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9640 - loss: 0.1051 - val_accuracy: 0.7815 - val_loss: 1.7844\n",
      "Epoch 371/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9646 - loss: 0.1019 - val_accuracy: 0.7797 - val_loss: 1.7813\n",
      "Epoch 372/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9665 - loss: 0.0989 - val_accuracy: 0.7788 - val_loss: 1.7803\n",
      "Epoch 373/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9642 - loss: 0.1033 - val_accuracy: 0.7810 - val_loss: 1.8074\n",
      "Epoch 374/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9645 - loss: 0.1003 - val_accuracy: 0.7902 - val_loss: 1.7952\n",
      "Epoch 375/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9647 - loss: 0.1006 - val_accuracy: 0.7815 - val_loss: 1.7965\n",
      "Epoch 376/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9647 - loss: 0.1036 - val_accuracy: 0.7809 - val_loss: 1.8144\n",
      "Epoch 377/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9652 - loss: 0.1005 - val_accuracy: 0.7841 - val_loss: 1.8545\n",
      "Epoch 378/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9657 - loss: 0.1005 - val_accuracy: 0.7883 - val_loss: 1.7729\n",
      "Epoch 379/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9660 - loss: 0.1006 - val_accuracy: 0.7776 - val_loss: 1.7540\n",
      "Epoch 380/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9642 - loss: 0.1037 - val_accuracy: 0.7802 - val_loss: 1.7945\n",
      "Epoch 381/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9662 - loss: 0.0992 - val_accuracy: 0.7736 - val_loss: 1.7899\n",
      "Epoch 382/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9641 - loss: 0.1020 - val_accuracy: 0.7684 - val_loss: 1.8691\n",
      "Epoch 383/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9635 - loss: 0.1033 - val_accuracy: 0.7845 - val_loss: 1.7162\n",
      "Epoch 384/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9648 - loss: 0.0991 - val_accuracy: 0.7815 - val_loss: 1.7888\n",
      "Epoch 385/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9646 - loss: 0.1028 - val_accuracy: 0.7755 - val_loss: 1.6965\n",
      "Epoch 386/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9647 - loss: 0.1021 - val_accuracy: 0.7755 - val_loss: 1.7938\n",
      "Epoch 387/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9655 - loss: 0.0993 - val_accuracy: 0.7766 - val_loss: 1.8389\n",
      "Epoch 388/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9658 - loss: 0.1000 - val_accuracy: 0.7751 - val_loss: 1.8213\n",
      "Epoch 389/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9664 - loss: 0.0989 - val_accuracy: 0.7757 - val_loss: 1.8089\n",
      "Epoch 390/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9648 - loss: 0.0998 - val_accuracy: 0.7726 - val_loss: 1.7602\n",
      "Epoch 391/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9653 - loss: 0.0993 - val_accuracy: 0.7757 - val_loss: 1.8144\n",
      "Epoch 392/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9671 - loss: 0.0958 - val_accuracy: 0.7863 - val_loss: 1.7719\n",
      "Epoch 393/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9651 - loss: 0.1017 - val_accuracy: 0.7830 - val_loss: 1.7695\n",
      "Epoch 394/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9658 - loss: 0.0988 - val_accuracy: 0.7833 - val_loss: 1.6472\n",
      "Epoch 395/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9655 - loss: 0.1006 - val_accuracy: 0.7834 - val_loss: 1.7998\n",
      "Epoch 396/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9665 - loss: 0.0997 - val_accuracy: 0.7777 - val_loss: 1.8344\n",
      "Epoch 397/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9654 - loss: 0.0970 - val_accuracy: 0.7754 - val_loss: 1.8445\n",
      "Epoch 398/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9664 - loss: 0.0961 - val_accuracy: 0.7839 - val_loss: 1.8358\n",
      "Epoch 399/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9664 - loss: 0.0972 - val_accuracy: 0.7707 - val_loss: 1.8991\n",
      "Epoch 400/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9655 - loss: 0.0996 - val_accuracy: 0.7809 - val_loss: 1.7725\n",
      "Epoch 401/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9668 - loss: 0.0952 - val_accuracy: 0.7777 - val_loss: 1.8320\n",
      "Epoch 402/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9655 - loss: 0.1018 - val_accuracy: 0.7760 - val_loss: 1.8438\n",
      "Epoch 403/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9659 - loss: 0.0990 - val_accuracy: 0.7724 - val_loss: 1.7483\n",
      "Epoch 404/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9657 - loss: 0.0999 - val_accuracy: 0.7781 - val_loss: 1.7859\n",
      "Epoch 405/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9668 - loss: 0.0982 - val_accuracy: 0.7739 - val_loss: 1.8230\n",
      "Epoch 406/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9660 - loss: 0.0978 - val_accuracy: 0.7785 - val_loss: 1.8770\n",
      "Epoch 407/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9652 - loss: 0.0995 - val_accuracy: 0.7829 - val_loss: 1.9029\n",
      "Epoch 408/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9654 - loss: 0.0998 - val_accuracy: 0.7750 - val_loss: 1.6621\n",
      "Epoch 409/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9648 - loss: 0.1043 - val_accuracy: 0.7820 - val_loss: 1.7223\n",
      "Epoch 410/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9652 - loss: 0.0994 - val_accuracy: 0.7714 - val_loss: 1.7530\n",
      "Epoch 411/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9665 - loss: 0.0956 - val_accuracy: 0.7797 - val_loss: 1.8582\n",
      "Epoch 412/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9659 - loss: 0.0968 - val_accuracy: 0.7783 - val_loss: 1.8130\n",
      "Epoch 413/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9662 - loss: 0.1011 - val_accuracy: 0.7780 - val_loss: 1.8341\n",
      "Epoch 414/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9673 - loss: 0.0966 - val_accuracy: 0.7710 - val_loss: 1.8632\n",
      "Epoch 415/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9658 - loss: 0.0976 - val_accuracy: 0.7808 - val_loss: 1.7925\n",
      "Epoch 416/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9665 - loss: 0.0962 - val_accuracy: 0.7765 - val_loss: 1.7772\n",
      "Epoch 417/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9675 - loss: 0.0963 - val_accuracy: 0.7782 - val_loss: 1.6734\n",
      "Epoch 418/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9654 - loss: 0.0999 - val_accuracy: 0.7776 - val_loss: 1.8575\n",
      "Epoch 419/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9661 - loss: 0.0964 - val_accuracy: 0.7777 - val_loss: 1.9017\n",
      "Epoch 420/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9676 - loss: 0.0964 - val_accuracy: 0.7802 - val_loss: 1.7509\n",
      "Epoch 421/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9669 - loss: 0.0961 - val_accuracy: 0.7850 - val_loss: 1.8642\n",
      "Epoch 422/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9667 - loss: 0.0976 - val_accuracy: 0.7824 - val_loss: 1.7634\n",
      "Epoch 423/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9669 - loss: 0.0945 - val_accuracy: 0.7781 - val_loss: 1.8107\n",
      "Epoch 424/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9646 - loss: 0.1027 - val_accuracy: 0.7820 - val_loss: 1.7913\n",
      "Epoch 425/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9677 - loss: 0.0964 - val_accuracy: 0.7772 - val_loss: 1.7183\n",
      "Epoch 426/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9682 - loss: 0.0926 - val_accuracy: 0.7759 - val_loss: 1.9056\n",
      "Epoch 427/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9662 - loss: 0.0982 - val_accuracy: 0.7802 - val_loss: 1.8309\n",
      "Epoch 428/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9658 - loss: 0.0977 - val_accuracy: 0.7771 - val_loss: 1.8196\n",
      "Epoch 429/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9677 - loss: 0.0934 - val_accuracy: 0.7768 - val_loss: 1.7794\n",
      "Epoch 430/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9664 - loss: 0.0964 - val_accuracy: 0.7717 - val_loss: 1.7965\n",
      "Epoch 431/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9669 - loss: 0.0964 - val_accuracy: 0.7759 - val_loss: 1.8775\n",
      "Epoch 432/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9654 - loss: 0.0982 - val_accuracy: 0.7762 - val_loss: 1.7816\n",
      "Epoch 433/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9666 - loss: 0.0960 - val_accuracy: 0.7845 - val_loss: 1.8134\n",
      "Epoch 434/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9673 - loss: 0.0973 - val_accuracy: 0.7845 - val_loss: 1.7760\n",
      "Epoch 435/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9658 - loss: 0.0992 - val_accuracy: 0.7740 - val_loss: 1.7716\n",
      "Epoch 436/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9678 - loss: 0.0957 - val_accuracy: 0.7819 - val_loss: 1.8945\n",
      "Epoch 437/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9664 - loss: 0.0955 - val_accuracy: 0.7756 - val_loss: 1.7988\n",
      "Epoch 438/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9674 - loss: 0.0954 - val_accuracy: 0.7782 - val_loss: 1.8403\n",
      "Epoch 439/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9681 - loss: 0.0911 - val_accuracy: 0.7764 - val_loss: 1.8578\n",
      "Epoch 440/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9672 - loss: 0.0944 - val_accuracy: 0.7715 - val_loss: 1.8441\n",
      "Epoch 441/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9673 - loss: 0.0939 - val_accuracy: 0.7851 - val_loss: 1.7837\n",
      "Epoch 442/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9668 - loss: 0.0948 - val_accuracy: 0.7714 - val_loss: 1.8896\n",
      "Epoch 443/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9675 - loss: 0.0940 - val_accuracy: 0.7839 - val_loss: 1.7629\n",
      "Epoch 444/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9676 - loss: 0.0929 - val_accuracy: 0.7781 - val_loss: 1.8216\n",
      "Epoch 445/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9669 - loss: 0.0933 - val_accuracy: 0.7807 - val_loss: 1.9030\n",
      "Epoch 446/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9655 - loss: 0.0982 - val_accuracy: 0.7788 - val_loss: 1.7583\n",
      "Epoch 447/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9670 - loss: 0.0966 - val_accuracy: 0.7837 - val_loss: 1.8582\n",
      "Epoch 448/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9676 - loss: 0.0937 - val_accuracy: 0.7734 - val_loss: 1.9445\n",
      "Epoch 449/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9677 - loss: 0.0934 - val_accuracy: 0.7792 - val_loss: 1.9044\n",
      "Epoch 450/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9669 - loss: 0.0946 - val_accuracy: 0.7799 - val_loss: 1.8953\n",
      "Epoch 451/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9667 - loss: 0.0953 - val_accuracy: 0.7843 - val_loss: 1.9255\n",
      "Epoch 452/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9674 - loss: 0.0945 - val_accuracy: 0.7806 - val_loss: 1.8370\n",
      "Epoch 453/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9674 - loss: 0.0944 - val_accuracy: 0.7702 - val_loss: 1.8518\n",
      "Epoch 454/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9672 - loss: 0.0935 - val_accuracy: 0.7810 - val_loss: 1.8464\n",
      "Epoch 455/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9664 - loss: 0.0956 - val_accuracy: 0.7782 - val_loss: 1.7694\n",
      "Epoch 456/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9663 - loss: 0.0953 - val_accuracy: 0.7731 - val_loss: 1.8718\n",
      "Epoch 457/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9679 - loss: 0.0947 - val_accuracy: 0.7738 - val_loss: 1.9364\n",
      "Epoch 458/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9669 - loss: 0.0961 - val_accuracy: 0.7816 - val_loss: 1.8098\n",
      "Epoch 459/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9674 - loss: 0.0943 - val_accuracy: 0.7726 - val_loss: 1.8850\n",
      "Epoch 460/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9666 - loss: 0.0942 - val_accuracy: 0.7727 - val_loss: 1.8730\n",
      "Epoch 461/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9679 - loss: 0.0919 - val_accuracy: 0.7820 - val_loss: 1.8070\n",
      "Epoch 462/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9682 - loss: 0.0936 - val_accuracy: 0.7826 - val_loss: 1.7727\n",
      "Epoch 463/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9683 - loss: 0.0881 - val_accuracy: 0.7689 - val_loss: 1.8701\n",
      "Epoch 464/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9671 - loss: 0.0939 - val_accuracy: 0.7735 - val_loss: 1.8692\n",
      "Epoch 465/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9672 - loss: 0.0924 - val_accuracy: 0.7780 - val_loss: 1.8494\n",
      "Epoch 466/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9649 - loss: 0.0981 - val_accuracy: 0.7764 - val_loss: 1.8480\n",
      "Epoch 467/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9679 - loss: 0.0932 - val_accuracy: 0.7691 - val_loss: 1.8581\n",
      "Epoch 468/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9678 - loss: 0.0936 - val_accuracy: 0.7719 - val_loss: 1.8962\n",
      "Epoch 469/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9680 - loss: 0.0924 - val_accuracy: 0.7740 - val_loss: 1.7426\n",
      "Epoch 470/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9683 - loss: 0.0913 - val_accuracy: 0.7800 - val_loss: 1.8038\n",
      "Epoch 471/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9681 - loss: 0.0929 - val_accuracy: 0.7708 - val_loss: 1.8598\n",
      "Epoch 472/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9679 - loss: 0.0916 - val_accuracy: 0.7830 - val_loss: 1.7831\n",
      "Epoch 473/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9681 - loss: 0.0936 - val_accuracy: 0.7818 - val_loss: 1.8199\n",
      "Epoch 474/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9693 - loss: 0.0900 - val_accuracy: 0.7789 - val_loss: 1.7879\n",
      "Epoch 475/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9676 - loss: 0.0904 - val_accuracy: 0.7757 - val_loss: 1.7922\n",
      "Epoch 476/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9688 - loss: 0.0906 - val_accuracy: 0.7804 - val_loss: 1.9644\n",
      "Epoch 477/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9666 - loss: 0.0955 - val_accuracy: 0.7717 - val_loss: 1.9140\n",
      "Epoch 478/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9676 - loss: 0.0948 - val_accuracy: 0.7746 - val_loss: 1.8035\n",
      "Epoch 479/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9680 - loss: 0.0939 - val_accuracy: 0.7775 - val_loss: 1.8872\n",
      "Epoch 480/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9675 - loss: 0.0940 - val_accuracy: 0.7788 - val_loss: 1.8778\n",
      "Epoch 481/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9680 - loss: 0.0930 - val_accuracy: 0.7855 - val_loss: 1.6876\n",
      "Epoch 482/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9658 - loss: 0.0944 - val_accuracy: 0.7737 - val_loss: 1.8886\n",
      "Epoch 483/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9659 - loss: 0.0961 - val_accuracy: 0.7746 - val_loss: 1.8797\n",
      "Epoch 484/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9704 - loss: 0.0881 - val_accuracy: 0.7794 - val_loss: 1.9623\n",
      "Epoch 485/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9681 - loss: 0.0924 - val_accuracy: 0.7668 - val_loss: 1.8627\n",
      "Epoch 486/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9676 - loss: 0.0941 - val_accuracy: 0.7754 - val_loss: 1.9706\n",
      "Epoch 487/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9658 - loss: 0.0982 - val_accuracy: 0.7732 - val_loss: 1.8621\n",
      "Epoch 488/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9684 - loss: 0.0894 - val_accuracy: 0.7748 - val_loss: 1.8955\n",
      "Epoch 489/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9672 - loss: 0.0938 - val_accuracy: 0.7845 - val_loss: 1.8731\n",
      "Epoch 490/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9695 - loss: 0.0889 - val_accuracy: 0.7830 - val_loss: 1.7991\n",
      "Epoch 491/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9688 - loss: 0.0894 - val_accuracy: 0.7796 - val_loss: 1.8315\n",
      "Epoch 492/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9700 - loss: 0.0877 - val_accuracy: 0.7831 - val_loss: 1.8714\n",
      "Epoch 493/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9683 - loss: 0.0906 - val_accuracy: 0.7838 - val_loss: 1.8581\n",
      "Epoch 494/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9685 - loss: 0.0923 - val_accuracy: 0.7790 - val_loss: 1.8490\n",
      "Epoch 495/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9675 - loss: 0.0942 - val_accuracy: 0.7725 - val_loss: 1.9662\n",
      "Epoch 496/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9682 - loss: 0.0917 - val_accuracy: 0.7840 - val_loss: 1.7199\n",
      "Epoch 497/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9686 - loss: 0.0901 - val_accuracy: 0.7831 - val_loss: 1.7464\n",
      "Epoch 498/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9660 - loss: 0.0950 - val_accuracy: 0.7786 - val_loss: 1.8571\n",
      "Epoch 499/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9664 - loss: 0.0975 - val_accuracy: 0.7869 - val_loss: 1.7979\n",
      "Epoch 500/500\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9687 - loss: 0.0910 - val_accuracy: 0.7788 - val_loss: 1.8005\n",
      "\u001B[1m616/616\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 787us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89556   0.86947   0.88232       927\n",
      "           1    0.98339   0.95793   0.97049       927\n",
      "           2    0.86027   0.89286   0.87626       924\n",
      "           3    0.96692   0.86659   0.91401       877\n",
      "           4    0.82784   0.71670   0.76827       946\n",
      "           5    0.61457   0.68191   0.64650       940\n",
      "           6    0.83825   0.93326   0.88321       944\n",
      "           7    0.77623   0.88000   0.82486       950\n",
      "           8    0.85843   0.29968   0.44427       951\n",
      "           9    0.67164   0.33981   0.45129       927\n",
      "          10    0.85984   0.72390   0.78604      1322\n",
      "          11    0.58785   0.96099   0.72948       564\n",
      "          12    0.88477   0.97106   0.92591       933\n",
      "          13    0.60794   0.90150   0.72618       934\n",
      "          14    0.62645   0.69043   0.65688       940\n",
      "          15    0.61472   0.76509   0.68171       928\n",
      "          16    0.98664   0.99792   0.99225       962\n",
      "          17    0.35556   0.26863   0.30604       953\n",
      "          18    0.65357   0.66808   0.66074       946\n",
      "          19    0.82264   0.74055   0.77944       952\n",
      "          20    0.52888   0.67050   0.59133       956\n",
      "\n",
      "    accuracy                        0.74684     19703\n",
      "   macro avg    0.75343   0.75223   0.73797     19703\n",
      "weighted avg    0.75771   0.74684   0.73811     19703\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T00:39:30.809354Z",
     "start_time": "2024-09-27T00:39:29.875288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(conv_mlp)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model\n",
    "with open(\"SubjectDependent/GeneratedTFLiteFilesAndOGModels/conv_mlp_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"TensorFlow Lite model has been saved as 'conv_mlp_model.tflite'\")\n",
    "\n",
    "# Optional: Save the Keras model\n",
    "conv_mlp.save(\"GeneratedTFLiteFilesAndOGModels/conv_mlp_model.h5\")\n",
    "print(\"Keras model has been saved as 'conv_mlp_model.h5'\")\n",
    "\n",
    "# If you still need to generate a C header file\n",
    "try:\n",
    "    from everywhereml.code_generators.tensorflow import convert_model\n",
    "\n",
    "    c_header = convert_model(conv_mlp, X_test, y_test, model_name='conv_mlp_model')\n",
    "\n",
    "    with open(\"SubjectDependent/GeneratedHeaderFiles/conv_mlp_model.h\", \"w\") as file:\n",
    "        file.write(c_header)\n",
    "\n",
    "    print(\"C header file has been saved as GeneratedHeaderFiles/conv_mlp_model.h'\")\n",
    "except ImportError:\n",
    "    print(\"everywhereml library not found. Skipping C header file generation.\")\n"
   ],
   "id": "b52dcf7c1dced840",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpo7pgwsgd/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpo7pgwsgd/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpo7pgwsgd'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 100, 9), dtype=tf.float32, name='keras_tensor_8')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 21), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  130758116849296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758116848944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758116849472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758112317104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758116851056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758112318864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758112315696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758112320800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758112314640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758112322384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1727397570.143308  116468 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1727397570.143321  116468 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "2024-09-27 06:39:30.143528: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpo7pgwsgd\n",
      "2024-09-27 06:39:30.143873: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-09-27 06:39:30.143881: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpo7pgwsgd\n",
      "2024-09-27 06:39:30.146992: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-09-27 06:39:30.147631: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-09-27 06:39:30.166967: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpo7pgwsgd\n",
      "2024-09-27 06:39:30.172989: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 29462 microseconds.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Lite model has been saved as 'conv_mlp_model.tflite'\n",
      "Keras model has been saved as 'conv_mlp_model.h5'\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7zdj70iq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7zdj70iq/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmp7zdj70iq'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 100, 9), dtype=tf.float32, name='keras_tensor_8')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 21), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  130758116849296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758116848944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758116849472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758112317104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758116851056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758112318864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758112315696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758112320800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758112314640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  130758112322384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1727397570.489396  116468 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1727397570.489408  116468 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "2024-09-27 06:39:30.489521: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp7zdj70iq\n",
      "2024-09-27 06:39:30.489873: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-09-27 06:39:30.489883: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmp7zdj70iq\n",
      "2024-09-27 06:39:30.493250: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-09-27 06:39:30.512298: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmp7zdj70iq\n",
      "2024-09-27 06:39:30.518075: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 28556 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C header file has been saved as GeneratedHeaderFiles/conv_mlp_model.h'\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T00:39:43.067011Z",
     "start_time": "2024-09-27T00:39:37.696935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing out the TFLite model when optimized for normal edge devices\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Loading the test data\n",
    "X_test = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/X_test.txt\")\n",
    "y_test = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/y_test.txt\")\n",
    "\n",
    "# Reshaping the input data\n",
    "n_timestep = 100\n",
    "n_features = 9\n",
    "X_test = X_test.reshape(X_test.shape[0], n_timestep, n_features)\n",
    "\n",
    "# Doing One-hot encode the labels\n",
    "lb = LabelBinarizer()\n",
    "y_test = lb.fit_transform(y_test)\n",
    "\n",
    "# Loading the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"SubjectDependent/GeneratedTFLiteFilesAndOGModels/conv_mlp_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Allocating input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data\n",
    "input_shape = input_details[0][\"shape\"]\n",
    "input_data = X_test\n",
    "\n",
    "# Now running predictions on every test sample\n",
    "y_pred_tflite = []\n",
    "for i in range(len(input_data)):\n",
    "    input_tensor = np.array(input_data[i], dtype=np.float32)\n",
    "    input_tensor = np.expand_dims(input_tensor, axis=0)\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], input_tensor)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "    y_pred_tflite.append(output_data)\n",
    "\n",
    "y_pred_tflite = np.vstack(y_pred_tflite)\n",
    "\n",
    "# Converting predictions to class labels\n",
    "y_pred_classes_tflite = np.argmax(y_pred_tflite, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculating the accuracy\n",
    "accuracy_tflite = accuracy_score(y_true_classes, y_pred_classes_tflite)\n",
    "print(f\"TFLite Model Accuracy: {accuracy_tflite:.5f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes_tflite, digits=5))\n",
    "\n",
    "try:\n",
    "    original_model = tf.keras.models.load_model(\"GeneratedTFLiteFilesAndOGModels/conv_mlp_model.h5\")\n",
    "    y_pred_original = original_model.predict(X_test)\n",
    "    y_pred_classes_original = np.argmax(y_pred_original, axis=1)\n",
    "    accuracy_original = accuracy_score(y_true_classes, y_pred_classes_original)\n",
    "    print(f\"\\nOriginal Keras Model Accuracy: {accuracy_original:.5f}\")\n",
    "    \n",
    "    prediction_match = np.mean(y_pred_classes_tflite == y_pred_classes_original)\n",
    "    print(f\"\\nPrediction Match between TFLite and Original model: {prediction_match:.5f}\")\n",
    "except:\n",
    "    print(\"\\nError Check your path\")"
   ],
   "id": "460956467dbb2a71",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite Model Accuracy: 0.74664\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89556   0.86947   0.88232       927\n",
      "           1    0.98230   0.95793   0.96996       927\n",
      "           2    0.86013   0.89177   0.87566       924\n",
      "           3    0.96692   0.86659   0.91401       877\n",
      "           4    0.82784   0.71670   0.76827       946\n",
      "           5    0.61398   0.68191   0.64617       940\n",
      "           6    0.83825   0.93326   0.88321       944\n",
      "           7    0.77551   0.88000   0.82446       950\n",
      "           8    0.85843   0.29968   0.44427       951\n",
      "           9    0.67094   0.33873   0.45018       927\n",
      "          10    0.85984   0.72390   0.78604      1322\n",
      "          11    0.58785   0.96099   0.72948       564\n",
      "          12    0.88465   0.96999   0.92536       933\n",
      "          13    0.60838   0.90150   0.72649       934\n",
      "          14    0.62705   0.69043   0.65722       940\n",
      "          15    0.61419   0.76509   0.68138       928\n",
      "          16    0.98563   0.99792   0.99174       962\n",
      "          17    0.35556   0.26863   0.30604       953\n",
      "          18    0.65357   0.66808   0.66074       946\n",
      "          19    0.82147   0.73950   0.77833       952\n",
      "          20    0.52888   0.67050   0.59133       956\n",
      "\n",
      "    accuracy                        0.74664     19703\n",
      "   macro avg    0.75319   0.75203   0.73774     19703\n",
      "weighted avg    0.75747   0.74664   0.73788     19703\n",
      "\n",
      "\u001B[1m616/616\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n",
      "\n",
      "Original Keras Model Accuracy: 0.75821\n",
      "\n",
      "Prediction Match between TFLite and Original model: 0.85748\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "addeaa0e8bcc4125"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
