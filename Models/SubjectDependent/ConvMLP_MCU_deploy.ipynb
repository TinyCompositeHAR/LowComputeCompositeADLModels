{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-27T03:52:17.280942Z",
     "start_time": "2024-09-27T03:50:30.049344Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Load the preprocessed data\n",
    "X_train = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/X_train.txt\")\n",
    "y_train = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/y_train.txt\")\n",
    "X_test = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/X_test.txt\")\n",
    "y_test = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/y_test.txt\")\n",
    "\n",
    "# Reshape the input data for Conv1D layers\n",
    "n_timestep = 100\n",
    "n_features = 9\n",
    "X_train = X_train.reshape(X_train.shape[0], n_timestep, n_features)\n",
    "X_test = X_test.reshape(X_test.shape[0], n_timestep, n_features)\n",
    "\n",
    "# One-hot encode the labels\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)\n",
    "\n",
    "\n",
    "def create_model(n_timesteps, n_features, n_outputs):\n",
    "    model = Sequential([\n",
    "        # Conv2D to emulate Conv1D by using height = 1 and kernel size (1, 3)\n",
    "        Conv2D(filters=64, kernel_size=(1, 3), activation=\"relu\", input_shape=(n_timesteps, n_features, 1)),\n",
    "        Conv2D(filters=64, kernel_size=(1, 3), activation=\"relu\"),\n",
    "\n",
    "        # Flatten instead of GlobalAveragePooling1D\n",
    "        Flatten(),\n",
    "\n",
    "        # Dense layers\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(n_outputs, activation=\"softmax\")\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "n_outputs = y_train.shape[1]\n",
    "conv_mlp = create_model(n_timestep, n_features, n_outputs)\n",
    "conv_mlp.compile(optimizer=Adam(learning_rate=0.001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "history = conv_mlp.fit(X_train, y_train, epochs=50, batch_size=512, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = conv_mlp.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true_classes, y_pred_classes, digits=5))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 09:50:30.240470: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-27 09:50:30.251252: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-27 09:50:30.254543: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-27 09:50:30.263350: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-27 09:50:30.778360: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/denuvo-drm/miniconda3/envs/CompositeADLRecognition/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727409052.040861  108114 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727409052.081612  108114 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727409052.086356  108114 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727409052.090438  108114 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727409052.093413  108114 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727409052.096014  108114 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727409052.200774  108114 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727409052.201916  108114 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727409052.203087  108114 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-27 09:50:52.204140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5800 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:0e:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727409053.450110  108477 service.cc:146] XLA service 0x75ae60005f10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1727409053.450143  108477 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2024-09-27 09:50:53.470005: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-27 09:50:53.570443: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-09-27 09:50:54.577798: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_455', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2024-09-27 09:50:54.694319: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_534', 324 bytes spill stores, 324 bytes spill loads\n",
      "\n",
      "2024-09-27 09:50:54.701300: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_534', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2024-09-27 09:50:54.773528: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_534', 336 bytes spill stores, 336 bytes spill loads\n",
      "\n",
      "2024-09-27 09:50:55.849570: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.20GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m 16/156\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.1614 - loss: 2.7300"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727409056.622464  108477 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m155/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.5313 - loss: 1.5099"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 09:51:00.160961: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.61GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 40ms/step - accuracy: 0.5333 - loss: 1.5032 - val_accuracy: 0.6735 - val_loss: 1.0511\n",
      "Epoch 2/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8378 - loss: 0.4964 - val_accuracy: 0.7192 - val_loss: 0.9992\n",
      "Epoch 3/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8818 - loss: 0.3622 - val_accuracy: 0.7264 - val_loss: 1.0263\n",
      "Epoch 4/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9026 - loss: 0.2921 - val_accuracy: 0.7249 - val_loss: 1.1122\n",
      "Epoch 5/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9259 - loss: 0.2268 - val_accuracy: 0.7246 - val_loss: 1.1609\n",
      "Epoch 6/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9361 - loss: 0.1919 - val_accuracy: 0.7439 - val_loss: 1.1554\n",
      "Epoch 7/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9486 - loss: 0.1553 - val_accuracy: 0.7259 - val_loss: 1.4123\n",
      "Epoch 8/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9552 - loss: 0.1362 - val_accuracy: 0.7452 - val_loss: 1.3910\n",
      "Epoch 9/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.9630 - loss: 0.1125 - val_accuracy: 0.7163 - val_loss: 1.5156\n",
      "Epoch 10/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.9616 - loss: 0.1138 - val_accuracy: 0.7269 - val_loss: 1.5004\n",
      "Epoch 11/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.9715 - loss: 0.0880 - val_accuracy: 0.7309 - val_loss: 1.5413\n",
      "Epoch 12/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.9733 - loss: 0.0815 - val_accuracy: 0.7243 - val_loss: 1.6398\n",
      "Epoch 13/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.9769 - loss: 0.0687 - val_accuracy: 0.7235 - val_loss: 1.7854\n",
      "Epoch 14/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.9755 - loss: 0.0714 - val_accuracy: 0.7132 - val_loss: 1.6983\n",
      "Epoch 15/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.9809 - loss: 0.0563 - val_accuracy: 0.7267 - val_loss: 1.8730\n",
      "Epoch 16/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.9813 - loss: 0.0565 - val_accuracy: 0.7237 - val_loss: 1.7706\n",
      "Epoch 17/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.9824 - loss: 0.0559 - val_accuracy: 0.7278 - val_loss: 2.0430\n",
      "Epoch 18/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.9852 - loss: 0.0447 - val_accuracy: 0.7280 - val_loss: 1.9996\n",
      "Epoch 19/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.9868 - loss: 0.0413 - val_accuracy: 0.7355 - val_loss: 2.1799\n",
      "Epoch 20/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9828 - loss: 0.0518 - val_accuracy: 0.7168 - val_loss: 2.1297\n",
      "Epoch 21/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.9847 - loss: 0.0473 - val_accuracy: 0.7216 - val_loss: 2.1260\n",
      "Epoch 22/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.9871 - loss: 0.0380 - val_accuracy: 0.7367 - val_loss: 2.1924\n",
      "Epoch 23/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9864 - loss: 0.0406 - val_accuracy: 0.7242 - val_loss: 2.3366\n",
      "Epoch 24/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 10ms/step - accuracy: 0.9923 - loss: 0.0254 - val_accuracy: 0.7218 - val_loss: 2.3066\n",
      "Epoch 25/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 12ms/step - accuracy: 0.9906 - loss: 0.0294 - val_accuracy: 0.7327 - val_loss: 2.2473\n",
      "Epoch 26/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 11ms/step - accuracy: 0.9941 - loss: 0.0193 - val_accuracy: 0.7169 - val_loss: 2.5033\n",
      "Epoch 27/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9866 - loss: 0.0382 - val_accuracy: 0.7341 - val_loss: 2.3808\n",
      "Epoch 28/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9870 - loss: 0.0380 - val_accuracy: 0.7378 - val_loss: 2.4914\n",
      "Epoch 29/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9860 - loss: 0.0404 - val_accuracy: 0.7167 - val_loss: 2.6695\n",
      "Epoch 30/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9931 - loss: 0.0211 - val_accuracy: 0.7229 - val_loss: 2.6582\n",
      "Epoch 31/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9935 - loss: 0.0207 - val_accuracy: 0.7216 - val_loss: 2.5407\n",
      "Epoch 32/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9897 - loss: 0.0326 - val_accuracy: 0.7346 - val_loss: 2.5702\n",
      "Epoch 33/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9930 - loss: 0.0217 - val_accuracy: 0.7333 - val_loss: 2.6906\n",
      "Epoch 34/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9920 - loss: 0.0233 - val_accuracy: 0.7126 - val_loss: 2.8044\n",
      "Epoch 35/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9917 - loss: 0.0269 - val_accuracy: 0.7139 - val_loss: 2.8984\n",
      "Epoch 36/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9897 - loss: 0.0304 - val_accuracy: 0.7212 - val_loss: 2.7420\n",
      "Epoch 37/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9916 - loss: 0.0241 - val_accuracy: 0.7234 - val_loss: 2.7244\n",
      "Epoch 38/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9929 - loss: 0.0216 - val_accuracy: 0.7280 - val_loss: 2.7186\n",
      "Epoch 39/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9938 - loss: 0.0195 - val_accuracy: 0.7267 - val_loss: 2.8036\n",
      "Epoch 40/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9928 - loss: 0.0208 - val_accuracy: 0.7339 - val_loss: 2.7300\n",
      "Epoch 41/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9943 - loss: 0.0160 - val_accuracy: 0.7230 - val_loss: 2.9279\n",
      "Epoch 42/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9908 - loss: 0.0276 - val_accuracy: 0.7187 - val_loss: 3.1011\n",
      "Epoch 43/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9920 - loss: 0.0234 - val_accuracy: 0.7362 - val_loss: 2.6845\n",
      "Epoch 44/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9931 - loss: 0.0202 - val_accuracy: 0.7419 - val_loss: 2.9102\n",
      "Epoch 45/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9937 - loss: 0.0188 - val_accuracy: 0.7185 - val_loss: 3.0369\n",
      "Epoch 46/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9911 - loss: 0.0274 - val_accuracy: 0.7218 - val_loss: 2.9228\n",
      "Epoch 47/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9944 - loss: 0.0167 - val_accuracy: 0.7339 - val_loss: 3.0435\n",
      "Epoch 48/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9955 - loss: 0.0130 - val_accuracy: 0.7239 - val_loss: 3.1493\n",
      "Epoch 49/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9941 - loss: 0.0169 - val_accuracy: 0.7289 - val_loss: 3.0050\n",
      "Epoch 50/50\n",
      "\u001B[1m156/156\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9915 - loss: 0.0261 - val_accuracy: 0.7345 - val_loss: 3.0756\n",
      "\u001B[1m616/616\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.84417   0.81230   0.82793       927\n",
      "           1    0.95321   0.94498   0.94908       927\n",
      "           2    0.81593   0.85390   0.83448       924\n",
      "           3    0.92790   0.67503   0.78152       877\n",
      "           4    0.66175   0.66385   0.66280       946\n",
      "           5    0.58521   0.66489   0.62251       940\n",
      "           6    0.71222   0.78390   0.74634       944\n",
      "           7    0.69138   0.78526   0.73534       950\n",
      "           8    0.69415   0.27445   0.39337       951\n",
      "           9    0.56848   0.23732   0.33486       927\n",
      "          10    0.85131   0.61498   0.71410      1322\n",
      "          11    0.56941   0.85816   0.68458       564\n",
      "          12    0.75763   0.90461   0.82462       933\n",
      "          13    0.63988   0.93790   0.76075       934\n",
      "          14    0.53878   0.54681   0.54277       940\n",
      "          15    0.58555   0.66379   0.62222       928\n",
      "          16    0.96278   0.99480   0.97853       962\n",
      "          17    0.35144   0.21721   0.26848       953\n",
      "          18    0.47310   0.49260   0.48265       946\n",
      "          19    0.64599   0.74370   0.69141       952\n",
      "          20    0.49476   0.74059   0.59321       956\n",
      "\n",
      "    accuracy                        0.68127     19703\n",
      "   macro avg    0.68214   0.68624   0.66912     19703\n",
      "weighted avg    0.68638   0.68127   0.66895     19703\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T03:52:24.821411Z",
     "start_time": "2024-09-27T03:52:17.292657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(conv_mlp)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model\n",
    "with open(\"SubjectDependent/GeneratedTFLiteFilesAndOGModels/conv_mlp_model_deploy.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"TensorFlow Lite model has been saved as 'conv_mlp_model_deploy.tflite'\")\n",
    "\n",
    "# Optional: Save the Keras model\n",
    "conv_mlp.save(\"GeneratedTFLiteFilesAndOGModels/conv_mlp_model_deploy.h5\")\n",
    "print(\"Keras model has been saved as 'conv_mlp_model_deploy.h5'\")\n",
    "\n",
    "# If you still need to generate a C header file\n",
    "try:\n",
    "    from everywhereml.code_generators.tensorflow import convert_model\n",
    "\n",
    "    c_header = convert_model(conv_mlp, X_test, y_test, model_name='conv_mlp_model_deploy')\n",
    "\n",
    "    with open(\"SubjectDependent/GeneratedHeaderFiles/conv_mlp_model.h\", \"w\") as file:\n",
    "        file.write(c_header)\n",
    "\n",
    "    print(\"C header file has been saved as GeneratedHeaderFiles/conv_mlp_model.h'\")\n",
    "except ImportError:\n",
    "    print(\"everywhereml library not found. Skipping C header file generation.\")\n"
   ],
   "id": "b52dcf7c1dced840",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnys6ipuf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnys6ipuf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpnys6ipuf'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 100, 9, 1), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 21), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  129399736352832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736356880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736355648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736359344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736354240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736360928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736354944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736362512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736353360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736364096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1727409137.582421  108114 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1727409137.582435  108114 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "2024-09-27 09:52:17.582631: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpnys6ipuf\n",
      "2024-09-27 09:52:17.582955: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-09-27 09:52:17.582963: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpnys6ipuf\n",
      "2024-09-27 09:52:17.585799: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-09-27 09:52:17.586383: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-09-27 09:52:17.619738: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpnys6ipuf\n",
      "2024-09-27 09:52:17.625559: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 42931 microseconds.\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Lite model has been saved as 'conv_mlp_model_deploy.tflite'\n",
      "Keras model has been saved as 'conv_mlp_model_deploy.h5'\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpebi2ged7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpebi2ged7/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpebi2ged7'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 100, 9, 1), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 21), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  129399736352832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736356880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736355648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736359344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736354240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736360928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736354944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736362512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736353360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129399736364096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1727409138.147023  108114 tf_tfl_flatbuffer_helpers.cc:392] Ignored output_format.\n",
      "W0000 00:00:1727409138.147034  108114 tf_tfl_flatbuffer_helpers.cc:395] Ignored drop_control_dependency.\n",
      "2024-09-27 09:52:18.147153: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpebi2ged7\n",
      "2024-09-27 09:52:18.147472: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-09-27 09:52:18.147480: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpebi2ged7\n",
      "2024-09-27 09:52:18.150408: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-09-27 09:52:18.201816: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpebi2ged7\n",
      "2024-09-27 09:52:18.207542: I tensorflow/cc/saved_model/loader.cc:462] SavedModel load for tags { serve }; Status: success: OK. Took 60391 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C header file has been saved as GeneratedHeaderFiles/conv_mlp_model.h'\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T03:52:29.072757Z",
     "start_time": "2024-09-27T03:52:24.988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing out the TFLite model when optimized for normal edge devices\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Loading the test data\n",
    "X_test = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/X_test.txt\")\n",
    "y_test = np.loadtxt(\"../Datasets/CAPP Dataset/SubjectIndependent50PercentOverlap/y_test.txt\")\n",
    "\n",
    "# Reshaping the input data\n",
    "n_timestep = 100\n",
    "n_features = 9\n",
    "X_test = X_test.reshape(X_test.shape[0], n_timestep, n_features)\n",
    "\n",
    "# Doing One-hot encode the labels\n",
    "lb = LabelBinarizer()\n",
    "y_test = lb.fit_transform(y_test)\n",
    "\n",
    "# Loading the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"SubjectDependent/GeneratedTFLiteFilesAndOGModels/conv_mlp_model_deploy.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Allocating input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data\n",
    "input_shape = input_details[0][\"shape\"]\n",
    "input_data = X_test\n",
    "\n",
    "# Now running predictions on every test sample\n",
    "y_pred_tflite = []\n",
    "for i in range(len(input_data)):\n",
    "    input_tensor = np.array(input_data[i], dtype=np.float32)\n",
    "    input_tensor = np.expand_dims(input_tensor, axis=0)\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], input_tensor)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "    y_pred_tflite.append(output_data)\n",
    "\n",
    "y_pred_tflite = np.vstack(y_pred_tflite)\n",
    "\n",
    "# Converting predictions to class labels\n",
    "y_pred_classes_tflite = np.argmax(y_pred_tflite, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculating the accuracy\n",
    "accuracy_tflite = accuracy_score(y_true_classes, y_pred_classes_tflite)\n",
    "print(f\"TFLite Model Accuracy: {accuracy_tflite:.5f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes_tflite, digits=5))\n",
    "\n",
    "try:\n",
    "    original_model = tf.keras.models.load_model(\"GeneratedTFLiteFilesAndOGModels/conv_mlp_model_deploy.h5\")\n",
    "    y_pred_original = original_model.predict(X_test)\n",
    "    y_pred_classes_original = np.argmax(y_pred_original, axis=1)\n",
    "    accuracy_original = accuracy_score(y_true_classes, y_pred_classes_original)\n",
    "    print(f\"\\nOriginal Keras Model Accuracy: {accuracy_original:.5f}\")\n",
    "\n",
    "    prediction_match = np.mean(y_pred_classes_tflite == y_pred_classes_original)\n",
    "    print(f\"\\nPrediction Match between TFLite and Original model: {prediction_match:.5f}\")\n",
    "except:\n",
    "    print(\"\\nError Check your path\")"
   ],
   "id": "460956467dbb2a71",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 0.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 34\u001B[0m\n\u001B[1;32m     32\u001B[0m input_tensor \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(input_data[i], dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m     33\u001B[0m input_tensor \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(input_tensor, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m---> 34\u001B[0m \u001B[43minterpreter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_details\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mindex\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m interpreter\u001B[38;5;241m.\u001B[39minvoke()\n\u001B[1;32m     36\u001B[0m output_data \u001B[38;5;241m=\u001B[39m interpreter\u001B[38;5;241m.\u001B[39mget_tensor(output_details[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[0;32m~/miniconda3/envs/CompositeADLRecognition/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:732\u001B[0m, in \u001B[0;36mInterpreter.set_tensor\u001B[0;34m(self, tensor_index, value)\u001B[0m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_tensor\u001B[39m(\u001B[38;5;28mself\u001B[39m, tensor_index, value):\n\u001B[1;32m    717\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Sets the value of the input tensor.\u001B[39;00m\n\u001B[1;32m    718\u001B[0m \n\u001B[1;32m    719\u001B[0m \u001B[38;5;124;03m  Note this copies data in `value`.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    730\u001B[0m \u001B[38;5;124;03m    ValueError: If the interpreter could not set the tensor.\u001B[39;00m\n\u001B[1;32m    731\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 732\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpreter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSetTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: Cannot set tensor: Dimension mismatch. Got 3 but expected 4 for input 0."
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "addeaa0e8bcc4125"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
